
@article{bing_supervised_2019,
	title = {Supervised Learning in {SNN} via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reaching Vehicle},
	volume = {13},
	issn = {1662-5218},
	url = {https://www.frontiersin.org/article/10.3389/fnbot.2019.00018/full},
	doi = {10.3389/fnbot.2019.00018},
	pages = {18},
	journaltitle = {Frontiers in Neurorobotics},
	shortjournal = {Front. Neurorobot.},
	author = {Bing, Zhenshan and Baumann, Ivan and Jiang, Zhuangyi and Huang, Kai and Cai, Caixia and Knoll, Alois},
	urldate = {2022-03-31},
	date = {2019-05-03},
	file = {Full Text:/home/max/Zotero/storage/ISZP26ET/Bing et al. - 2019 - Supervised Learning in SNN via Reward-Modulated Sp.pdf:application/pdf},
}

@inproceedings{huang_optimizing_2017,
	title = {Optimizing the dynamics of spiking networks for decoding and control},
	doi = {10.23919/ACC.2017.7963374},
	abstract = {In this paper, an optimization-based approach to construct spiking networks for the purposes of decoding and control is presented. Specifically, we postulate a simple objective function wherein a network of interacting, primitive spiking units is decoded in order to drive a linear system along a prescribed trajectory. The units are assumed to spike only if doing so will decrease a specified objective function. The optimization gives rise to an emergent network of neurons with diffusive dynamics and a threshold-based spiking rule that bears resemblance to the Integrate and Fire neural model.},
	eventtitle = {2017 American Control Conference ({ACC})},
	pages = {2792--2798},
	booktitle = {2017 American Control Conference ({ACC})},
	author = {Huang, Fuqiang and Riehl, James and Ching, {ShiNung}},
	date = {2017-05},
	note = {{ISSN}: 2378-5861},
	keywords = {Biological neural networks, Control systems, Decoding, Linear programming, Linear systems, Neurons, Optimization},
	file = {IEEE Xplore Abstract Record:/home/max/Zotero/storage/GXAYJL4Y/7963374.html:text/html;IEEE Xplore Full Text PDF:/home/max/Zotero/storage/JQTNHXJB/Huang et al. - 2017 - Optimizing the dynamics of spiking networks for de.pdf:application/pdf},
}

@article{boerlin_predictive_2013,
	title = {Predictive Coding of Dynamical Variables in Balanced Spiking Networks},
	volume = {9},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003258},
	doi = {10.1371/journal.pcbi.1003258},
	abstract = {Two observations about the cortex have puzzled neuroscientists for a long time. First, neural responses are highly variable. Second, the level of excitation and inhibition received by each neuron is tightly balanced at all times. Here, we demonstrate that both properties are necessary consequences of neural networks that represent information efficiently in their spikes. We illustrate this insight with spiking networks that represent dynamical variables. Our approach is based on two assumptions: We assume that information about dynamical variables can be read out linearly from neural spike trains, and we assume that neurons only fire a spike if that improves the representation of the dynamical variables. Based on these assumptions, we derive a network of leaky integrate-and-fire neurons that is able to implement arbitrary linear dynamical systems. We show that the membrane voltage of the neurons is equivalent to a prediction error about a common population-level signal. Among other things, our approach allows us to construct an integrator network of spiking neurons that is robust against many perturbations. Most importantly, neural variability in our networks cannot be equated to noise. Despite exhibiting the same single unit properties as widely used population code models (e.g. tuning curves, Poisson distributed spike trains), balanced networks are orders of magnitudes more reliable. Our approach suggests that spikes do matter when considering how the brain computes, and that the reliability of cortical representations could have been strongly underestimated.},
	pages = {e1003258},
	number = {11},
	journaltitle = {{PLOS} Computational Biology},
	shortjournal = {{PLOS} Computational Biology},
	author = {Boerlin, Martin and Machens, Christian K. and Denève, Sophie},
	urldate = {2022-09-20},
	date = {2013-11-14},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Neurons, Action potentials, Dynamical systems, Membrane potential, Network analysis, Neural networks, Neuronal tuning, Sensory perception},
	file = {Full Text PDF:/home/max/Zotero/storage/PA8LXANX/Boerlin et al. - 2013 - Predictive Coding of Dynamical Variables in Balanc.pdf:application/pdf;Snapshot:/home/max/Zotero/storage/ACMFCVFE/article.html:text/html},
}

@article{brendel_learning_2020,
	title = {Learning to represent signals spike by spike},
	volume = {16},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007692},
	doi = {10.1371/journal.pcbi.1007692},
	abstract = {Networks based on coordinated spike coding can encode information with high efficiency in the spike trains of individual neurons. These networks exhibit single-neuron variability and tuning curves as typically observed in cortex, but paradoxically coincide with a precise, non-redundant spike-based population code. However, it has remained unclear whether the specific synaptic connectivities required in these networks can be learnt with local learning rules. Here, we show how to learn the required architecture. Using coding efficiency as an objective, we derive spike-timing-dependent learning rules for a recurrent neural network, and we provide exact solutions for the networks’ convergence to an optimal state. As a result, we deduce an entire network from its input distribution and a firing cost. After learning, basic biophysical quantities such as voltages, firing thresholds, excitation, inhibition, or spikes acquire precise functional interpretations.},
	pages = {e1007692},
	number = {3},
	journaltitle = {{PLOS} Computational Biology},
	shortjournal = {{PLOS} Computational Biology},
	author = {Brendel, Wieland and Bourdoukan, Ralph and Vertechi, Pietro and Machens, Christian K. and Denève, Sophie},
	urldate = {2022-09-20},
	date = {2020-03-16},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Neurons, Action potentials, Membrane potential, Neural networks, Neuronal tuning, Coding mechanisms, Signaling networks, Speech signal processing},
	file = {Full Text PDF:/home/max/Zotero/storage/CZV96R6W/Brendel et al. - 2020 - Learning to represent signals spike by spike.pdf:application/pdf;Snapshot:/home/max/Zotero/storage/4QSKUIUN/article.html:text/html},
}

@online{noauthor_elsevier_nodate,
	title = {Elsevier Enhanced Reader},
	url = {https://reader.elsevier.com/reader/sd/pii/S0893608019303181?token=C6EE78C8DB33212369B121653DF2B3F9D33D1824C163EE4735825EDD496E32302EB459DD90100FEFE7959B6E5B19B438&originRegion=eu-west-1&originCreation=20220920145904},
	urldate = {2022-09-20},
	langid = {english},
	doi = {10.1016/j.neunet.2019.09.036},
	file = {Full Text:/home/max/Zotero/storage/SZC73ZSZ/Elsevier Enhanced Reader.pdf:application/pdf;Snapshot:/home/max/Zotero/storage/AE8SZ8GB/S0893608019303181.html:text/html},
}

@article{taherkhani_review_2020,
	title = {A review of learning in biologically plausible spiking neural networks},
	volume = {122},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608019303181},
	doi = {10.1016/j.neunet.2019.09.036},
	abstract = {Artificial neural networks have been used as a powerful processing tool in various areas such as pattern recognition, control, robotics, and bioinformatics. Their wide applicability has encouraged researchers to improve artificial neural networks by investigating the biological brain. Neurological research has significantly progressed in recent years and continues to reveal new characteristics of biological neurons. New technologies can now capture temporal changes in the internal activity of the brain in more detail and help clarify the relationship between brain activity and the perception of a given stimulus. This new knowledge has led to a new type of artificial neural network, the Spiking Neural Network ({SNN}), that draws more faithfully on biological properties to provide higher processing abilities. A review of recent developments in learning of spiking neurons is presented in this paper. First the biological background of {SNN} learning algorithms is reviewed. The important elements of a learning algorithm such as the neuron model, synaptic plasticity, information encoding and {SNN} topologies are then presented. Then, a critical review of the state-of-the-art learning algorithms for {SNNs} using single and multiple spikes is presented. Additionally, deep spiking neural networks are reviewed, and challenges and opportunities in the {SNN} field are discussed.},
	pages = {253--272},
	journaltitle = {Neural Networks},
	shortjournal = {Neural Networks},
	author = {Taherkhani, Aboozar and Belatreche, Ammar and Li, Yuhua and Cosma, Georgina and Maguire, Liam P. and {McGinnity}, T. M.},
	urldate = {2022-09-20},
	date = {2020-02-01},
	langid = {english},
	keywords = {Learning, Spiking neural network ({SNN}), Synaptic plasticity},
	file = {Full Text:/home/max/Zotero/storage/HKRNSUWU/Taherkhani et al. - 2020 - A review of learning in biologically plausible spi.pdf:application/pdf;ScienceDirect Snapshot:/home/max/Zotero/storage/CYGAQY8Z/S0893608019303181.html:text/html},
}

@article{zheng_introductory_2022,
	title = {An Introductory Review of Spiking Neural Network and Artificial Neural Network: From Biological Intelligence to Artificial Intelligence},
	url = {http://arxiv.org/abs/2204.07519},
	shorttitle = {An Introductory Review of Spiking Neural Network and Artificial Neural Network},
	abstract = {Recently, stemming from the rapid development of artificial intelligence, which has gained expansive success in pattern recognition, robotics, and bioinformatics, neuroscience is also gaining tremendous progress. A kind of spiking neural network with biological interpretability is gradually receiving wide attention, and this kind of neural network is also regarded as one of the directions toward general artificial intelligence. This review introduces the following sections, the biological background of spiking neurons and the theoretical basis, different neuronal models, the connectivity of neural circuits, the mainstream neural network learning mechanisms and network architectures, etc. This review hopes to attract different researchers and advance the development of brain-inspired intelligence and artificial intelligence.},
	journaltitle = {{arXiv}:2204.07519 [cs]},
	author = {Zheng, Shengjie and Qian, Lang and Li, Pingsheng and He, Chenggang and Qin, Xiaoqin and Li, Xiaojian},
	urldate = {2022-09-20},
	date = {2022-04-09},
	eprinttype = {arxiv},
	eprint = {2204.07519},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/home/max/Zotero/storage/3PER3Y9Y/Zheng et al. - 2022 - An Introductory Review of Spiking Neural Network a.pdf:application/pdf;arXiv.org Snapshot:/home/max/Zotero/storage/CZ94M8PX/2204.html:text/html},
}

@article{izhikevich_simple_2003,
	title = {Simple model of spiking neurons},
	volume = {14},
	issn = {1941-0093},
	doi = {10.1109/TNN.2003.820440},
	abstract = {A model is presented that reproduces spiking and bursting behavior of known types of cortical neurons. The model combines the biologically plausibility of Hodgkin-Huxley-type dynamics and the computational efficiency of integrate-and-fire neurons. Using this model, one can simulate tens of thousands of spiking cortical neurons in real time (1 ms resolution) using a desktop {PC}.},
	pages = {1569--1572},
	number = {6},
	journaltitle = {{IEEE} Transactions on Neural Networks},
	author = {Izhikevich, E.M.},
	date = {2003-11},
	note = {Conference Name: {IEEE} Transactions on Neural Networks},
	keywords = {Neurons, Bifurcation, Biological system modeling, Biology computing, Biomembranes, Brain modeling, Computational modeling, Large-scale systems, Mathematical analysis, Mathematical model},
	file = {Full Text:/home/max/Zotero/storage/86M9DHRU/Izhikevich - 2003 - Simple model of spiking neurons.pdf:application/pdf;IEEE Xplore Abstract Record:/home/max/Zotero/storage/VARGU5K2/1257420.html:text/html},
}

@book{johnston_foundations_1995,
	location = {Cambridge, Mass},
	title = {Foundations of cellular neurophysiology},
	isbn = {978-0-262-10053-3},
	pagetotal = {676},
	publisher = {{MIT} Press},
	author = {Johnston, Daniel and Wu, Samuel Miao-sin},
	date = {1995},
	keywords = {Neurons, Ion Channels, Neurophysiology, physiology, Synaptic Transmission},
}

@article{hodgkin_quantitative_1952,
	title = {A quantitative description of membrane current and its application to conduction and excitation in nerve},
	volume = {117},
	issn = {1469-7793},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1952.sp004764},
	doi = {10.1113/jphysiol.1952.sp004764},
	pages = {500--544},
	number = {4},
	journaltitle = {The Journal of Physiology},
	author = {Hodgkin, A. L. and Huxley, A. F.},
	urldate = {2022-09-21},
	date = {1952},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1113/jphysiol.1952.sp004764},
	file = {Full Text PDF:/home/max/Zotero/storage/HZXTUGM9/Hodgkin and Huxley - 1952 - A quantitative description of membrane current and.pdf:application/pdf;Snapshot:/home/max/Zotero/storage/5SKVB6M9/jphysiol.1952.html:text/html},
}

@article{azevedo_equal_2009,
	title = {Equal numbers of neuronal and nonneuronal cells make the human brain an isometrically scaled-up primate brain},
	volume = {513},
	issn = {1096-9861},
	doi = {10.1002/cne.21974},
	abstract = {The human brain is often considered to be the most cognitively capable among mammalian brains and to be much larger than expected for a mammal of our body size. Although the number of neurons is generally assumed to be a determinant of computational power, and despite the widespread quotes that the human brain contains 100 billion neurons and ten times more glial cells, the absolute number of neurons and glial cells in the human brain remains unknown. Here we determine these numbers by using the isotropic fractionator and compare them with the expected values for a human-sized primate. We find that the adult male human brain contains on average 86.1 +/- 8.1 billion {NeuN}-positive cells ("neurons") and 84.6 +/- 9.8 billion {NeuN}-negative ("nonneuronal") cells. With only 19\% of all neurons located in the cerebral cortex, greater cortical size (representing 82\% of total brain mass) in humans compared with other primates does not reflect an increased relative number of cortical neurons. The ratios between glial cells and neurons in the human brain structures are similar to those found in other primates, and their numbers of cells match those expected for a primate of human proportions. These findings challenge the common view that humans stand out from other primates in their brain composition and indicate that, with regard to numbers of neuronal and nonneuronal cells, the human brain is an isometrically scaled-up primate brain.},
	pages = {532--541},
	number = {5},
	journaltitle = {The Journal of Comparative Neurology},
	shortjournal = {J Comp Neurol},
	author = {Azevedo, Frederico A. C. and Carvalho, Ludmila R. B. and Grinberg, Lea T. and Farfel, José Marcelo and Ferretti, Renata E. L. and Leite, Renata E. P. and Jacob Filho, Wilson and Lent, Roberto and Herculano-Houzel, Suzana},
	date = {2009-04-10},
	pmid = {19226510},
	keywords = {Neurons, Aged, Antigens, Nuclear, Brain, Cerebral Cortex, Humans, Immunohistochemistry, Male, Middle Aged, Nerve Tissue Proteins, Neuroglia},
}

@article{huang_dynamics_2019,
	title = {Dynamics and Control in Spiking Neural Networks},
	url = {https://openscholarship.wustl.edu/eng_etds/495},
	doi = {10.7936/YA3F-RK28},
	author = {Huang, Fuqiang},
	urldate = {2022-10-14},
	date = {2019-12-15},
	note = {Publisher: Washington University in St. Louis},
}

@article{deneve_efficient_2016,
	title = {Efficient codes and balanced networks},
	volume = {19},
	issn = {1097-6256, 1546-1726},
	url = {http://www.nature.com/articles/nn.4243},
	doi = {10.1038/nn.4243},
	pages = {375--382},
	number = {3},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat Neurosci},
	author = {Denève, Sophie and Machens, Christian K},
	urldate = {2022-10-18},
	date = {2016-03},
	langid = {english},
}

@article{huang_spiking_2019,
	title = {Spiking networks as efficient distributed controllers},
	volume = {113},
	issn = {0340-1200, 1432-0770},
	url = {http://link.springer.com/10.1007/s00422-018-0769-7},
	doi = {10.1007/s00422-018-0769-7},
	pages = {179--190},
	number = {1},
	journaltitle = {Biological Cybernetics},
	shortjournal = {Biol Cybern},
	author = {Huang, Fuqiang and Ching, {ShiNung}},
	urldate = {2022-10-23},
	date = {2019-04},
	langid = {english},
}

@article{tanaka_recent_2019,
	title = {Recent advances in physical reservoir computing: A review},
	volume = {115},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608019300784},
	doi = {10.1016/j.neunet.2019.03.005},
	shorttitle = {Recent advances in physical reservoir computing},
	pages = {100--123},
	journaltitle = {Neural Networks},
	shortjournal = {Neural Networks},
	author = {Tanaka, Gouhei and Yamane, Toshiyuki and Héroux, Jean Benoit and Nakane, Ryosho and Kanazawa, Naoki and Takeda, Seiji and Numata, Hidetoshi and Nakano, Daiju and Hirose, Akira},
	urldate = {2022-10-29},
	date = {2019-07},
	langid = {english},
	file = {Full Text:/home/max/Zotero/storage/HCM2U7AB/Tanaka et al. - 2019 - Recent advances in physical reservoir computing A.pdf:application/pdf},
}

@inbook{cooper_liquid_2011,
	title = {Liquid State Machines: Motivation, Theory, and Applications},
	isbn = {978-1-84816-245-7 978-1-84816-277-8},
	url = {http://www.worldscientific.com/doi/abs/10.1142/9781848162778_0008},
	shorttitle = {Liquid State Machines},
	pages = {275--296},
	booktitle = {Computability in Context},
	publisher = {{IMPERIAL} {COLLEGE} {PRESS}},
	author = {Maass, Wolfgang},
	bookauthor = {Cooper, S Barry and Sorbi, Andrea},
	urldate = {2022-10-31},
	date = {2011-02},
	langid = {english},
	doi = {10.1142/9781848162778_0008},
}

@article{maass_computational_2004,
	title = {On the computational power of circuits of spiking neurons},
	volume = {69},
	issn = {00220000},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022000004000406},
	doi = {10.1016/j.jcss.2004.04.001},
	pages = {593--616},
	number = {4},
	journaltitle = {Journal of Computer and System Sciences},
	shortjournal = {Journal of Computer and System Sciences},
	author = {Maass, Wolfgang and Markram, Henry},
	urldate = {2022-11-07},
	date = {2004-12},
	langid = {english},
	file = {Full Text:/home/max/Zotero/storage/SAY2ARZX/Maass and Markram - 2004 - On the computational power of circuits of spiking .pdf:application/pdf},
}

@book{dayan_theoretical_2001,
	location = {Cambridge, Mass},
	title = {Theoretical neuroscience: computational and mathematical modeling of neural systems},
	isbn = {978-0-262-04199-7},
	series = {Computational neuroscience},
	shorttitle = {Theoretical neuroscience},
	pagetotal = {460},
	publisher = {Massachusetts Institute of Technology Press},
	author = {Dayan, Peter and Abbott, L. F.},
	date = {2001},
	langid = {english},
	keywords = {Computational neuroscience, Computer simulation, Human information processing, Neural networks (Neurobiology)},
	file = {Dayan and Abbott - 2001 - Theoretical neuroscience computational and mathem.pdf:/home/max/Zotero/storage/ZXQ2I2D2/Dayan and Abbott - 2001 - Theoretical neuroscience computational and mathem.pdf:application/pdf},
}

@article{maass_computational_2007,
	title = {Computational Aspects of Feedback in Neural Circuits},
	volume = {3},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.0020165},
	doi = {10.1371/journal.pcbi.0020165},
	pages = {e165},
	number = {1},
	journaltitle = {{PLoS} Computational Biology},
	shortjournal = {{PLoS} Comput Biol},
	author = {Maass, Wolfgang and Joshi, Prashant and Sontag, Eduardo D},
	editor = {Kotter, Rolf},
	urldate = {2022-11-07},
	date = {2007-01-19},
	langid = {english},
	file = {Full Text:/home/max/Zotero/storage/JKI7GQUS/Maass et al. - 2007 - Computational Aspects of Feedback in Neural Circui.pdf:application/pdf},
}

@article{verstraeten_experimental_2007,
	title = {An experimental unification of reservoir computing methods},
	volume = {20},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S089360800700038X},
	doi = {10.1016/j.neunet.2007.04.003},
	pages = {391--403},
	number = {3},
	journaltitle = {Neural Networks},
	shortjournal = {Neural Networks},
	author = {Verstraeten, D. and Schrauwen, B. and D’Haene, M. and Stroobandt, D.},
	urldate = {2022-11-07},
	date = {2007-04},
	langid = {english},
}

@report{rullan_buxo_poisson_2019,
	title = {Poisson balanced spiking networks},
	url = {http://biorxiv.org/lookup/doi/10.1101/836601},
	abstract = {Abstract
          An important problem in computational neuroscience is to understand how networks of spiking neurons can carry out various computations underlying behavior. Balanced spiking networks ({BSNs}) provide a powerful framework for implementing arbitrary linear dynamical systems in networks of integrate-and-fire neurons (Boerlin et al. [1]). However, the classic {BSN} model requires near-instantaneous transmission of spikes between neurons, which is biologically implausible. Introducing realistic synaptic delays leads to an pathological regime known as “ping-ponging”, in which different populations spike maximally in alternating time bins, causing network output to overshoot the target solution. Here we document this phenomenon and provide a novel solution: we show that a network can have realistic synaptic delays while maintaining accuracy and stability if neurons are endowed with conditionally Poisson firing. Formally, we propose two alternate formulations of Poisson balanced spiking networks: (1) a “local” framework, which replaces the hard integrate-and-fire spiking rule within each neuron by a “soft” threshold function, such that firing probability grows as a smooth nonlinear function of membrane potential; and (2) a “population” framework, which reformulates the {BSN} objective function in terms of expected spike counts over the entire population. We show that both approaches offer improved robustness, allowing for accurate implementation of network dynamics with realistic synaptic delays between neurons. Moreover, both models produce positive correlations between similarly tuned neurons, a feature of real neural populations that is not found in the original {BSN}. This work unifies balanced spiking networks with Poisson generalized linear models and suggests several promising avenues for future research.},
	institution = {Neuroscience},
	type = {preprint},
	author = {Rullán Buxó, Camille E. and Pillow, Jonathan W.},
	urldate = {2022-11-07},
	date = {2019-11-09},
	langid = {english},
	doi = {10.1101/836601},
	file = {Full Text:/home/max/Zotero/storage/GY3X7XG9/Rullán Buxó and Pillow - 2019 - Poisson balanced spiking networks.pdf:application/pdf},
}

@article{andrew_spiking_2003,
	title = {Spiking Neuron Models: Single Neurons, Populations, Plasticity},
	volume = {32},
	issn = {0368-492X},
	url = {https://www.emerald.com/insight/content/doi/10.1108/k.2003.06732gae.003/full/html},
	doi = {10.1108/k.2003.06732gae.003},
	shorttitle = {Spiking Neuron Models},
	number = {7},
	journaltitle = {Kybernetes},
	author = {Andrew, Alex M.},
	urldate = {2022-11-15},
	date = {2003-10-01},
	langid = {english},
}

@article{almomani_comparative_2019,
	title = {A comparative study on spiking neural network encoding schema: implemented with cloud computing},
	volume = {22},
	issn = {1386-7857, 1573-7543},
	url = {http://link.springer.com/10.1007/s10586-018-02891-0},
	doi = {10.1007/s10586-018-02891-0},
	shorttitle = {A comparative study on spiking neural network encoding schema},
	pages = {419--433},
	number = {2},
	journaltitle = {Cluster Computing},
	shortjournal = {Cluster Comput},
	author = {Almomani, Ammar and Alauthman, Mohammad and Alweshah, Mohammed and Dorgham, O. and Albalas, Firas},
	urldate = {2022-11-15},
	date = {2019-06},
	langid = {english},
}

@article{adrian_impulses_1926,
	title = {The impulses produced by sensory nerve-endings: Part {II}. The response of a Single End-Organ},
	volume = {61},
	issn = {00223751},
	url = {https://onlinelibrary.wiley.com/doi/10.1113/jphysiol.1926.sp002281},
	doi = {10.1113/jphysiol.1926.sp002281},
	shorttitle = {The impulses produced by sensory nerve-endings},
	pages = {151--171},
	number = {2},
	journaltitle = {The Journal of Physiology},
	author = {Adrian, E. D. and Zotterman, Yngve},
	urldate = {2022-11-16},
	date = {1926-04-23},
	langid = {english},
	file = {Full Text:/home/max/Zotero/storage/GDHUCEUY/Adrian and Zotterman - 1926 - The impulses produced by sensory nerve-endings Pa.pdf:application/pdf},
}

@article{brette_philosophy_2015,
	title = {Philosophy of the Spike: Rate-Based vs. Spike-Based Theories of the Brain},
	volume = {9},
	issn = {1662-5137},
	url = {http://journal.frontiersin.org/Article/10.3389/fnsys.2015.00151/abstract},
	doi = {10.3389/fnsys.2015.00151},
	shorttitle = {Philosophy of the Spike},
	journaltitle = {Frontiers in Systems Neuroscience},
	shortjournal = {Front. Syst. Neurosci.},
	author = {Brette, Romain},
	urldate = {2022-11-16},
	date = {2015-11-10},
	file = {Full Text:/home/max/Zotero/storage/5T6FKJCM/Brette - 2015 - Philosophy of the Spike Rate-Based vs. Spike-Base.pdf:application/pdf},
}
