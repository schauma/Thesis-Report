
@article{bing_supervised_2019,
	title = {Supervised {Learning} in {SNN} via {Reward}-{Modulated} {Spike}-{Timing}-{Dependent} {Plasticity} for a {Target} {Reaching} {Vehicle}},
	volume = {13},
	issn = {1662-5218},
	url = {https://www.frontiersin.org/article/10.3389/fnbot.2019.00018/full},
	doi = {10.3389/fnbot.2019.00018},
	urldate = {2022-03-31},
	journal = {Frontiers in Neurorobotics},
	author = {Bing, Zhenshan and Baumann, Ivan and Jiang, Zhuangyi and Huang, Kai and Cai, Caixia and Knoll, Alois},
	month = may,
	year = {2019},
	pages = {18},
	file = {Full Text:/home/max/Zotero/storage/ISZP26ET/Bing et al. - 2019 - Supervised Learning in SNN via Reward-Modulated Sp.pdf:application/pdf},
}

@inproceedings{huang_optimizing_2017,
	title = {Optimizing the dynamics of spiking networks for decoding and control},
	doi = {10.23919/ACC.2017.7963374},
	abstract = {In this paper, an optimization-based approach to construct spiking networks for the purposes of decoding and control is presented. Specifically, we postulate a simple objective function wherein a network of interacting, primitive spiking units is decoded in order to drive a linear system along a prescribed trajectory. The units are assumed to spike only if doing so will decrease a specified objective function. The optimization gives rise to an emergent network of neurons with diffusive dynamics and a threshold-based spiking rule that bears resemblance to the Integrate and Fire neural model.},
	booktitle = {2017 {American} {Control} {Conference} ({ACC})},
	author = {Huang, Fuqiang and Riehl, James and Ching, ShiNung},
	month = may,
	year = {2017},
	note = {ISSN: 2378-5861},
	keywords = {Biological neural networks, Control systems, Decoding, Linear programming, Linear systems, Neurons, Optimization},
	pages = {2792--2798},
	file = {IEEE Xplore Abstract Record:/home/max/Zotero/storage/GXAYJL4Y/7963374.html:text/html;IEEE Xplore Full Text PDF:/home/max/Zotero/storage/JQTNHXJB/Huang et al. - 2017 - Optimizing the dynamics of spiking networks for de.pdf:application/pdf},
}

@article{boerlin_predictive_2013,
	title = {Predictive {Coding} of {Dynamical} {Variables} in {Balanced} {Spiking} {Networks}},
	volume = {9},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003258},
	doi = {10.1371/journal.pcbi.1003258},
	abstract = {Two observations about the cortex have puzzled neuroscientists for a long time. First, neural responses are highly variable. Second, the level of excitation and inhibition received by each neuron is tightly balanced at all times. Here, we demonstrate that both properties are necessary consequences of neural networks that represent information efficiently in their spikes. We illustrate this insight with spiking networks that represent dynamical variables. Our approach is based on two assumptions: We assume that information about dynamical variables can be read out linearly from neural spike trains, and we assume that neurons only fire a spike if that improves the representation of the dynamical variables. Based on these assumptions, we derive a network of leaky integrate-and-fire neurons that is able to implement arbitrary linear dynamical systems. We show that the membrane voltage of the neurons is equivalent to a prediction error about a common population-level signal. Among other things, our approach allows us to construct an integrator network of spiking neurons that is robust against many perturbations. Most importantly, neural variability in our networks cannot be equated to noise. Despite exhibiting the same single unit properties as widely used population code models (e.g. tuning curves, Poisson distributed spike trains), balanced networks are orders of magnitudes more reliable. Our approach suggests that spikes do matter when considering how the brain computes, and that the reliability of cortical representations could have been strongly underestimated.},
	language = {en},
	number = {11},
	urldate = {2022-09-20},
	journal = {PLOS Computational Biology},
	author = {Boerlin, Martin and Machens, Christian K. and Denève, Sophie},
	month = nov,
	year = {2013},
	note = {Publisher: Public Library of Science},
	keywords = {Action potentials, Dynamical systems, Membrane potential, Network analysis, Neural networks, Neuronal tuning, Neurons, Sensory perception},
	pages = {e1003258},
	file = {Full Text PDF:/home/max/Zotero/storage/PA8LXANX/Boerlin et al. - 2013 - Predictive Coding of Dynamical Variables in Balanc.pdf:application/pdf;Snapshot:/home/max/Zotero/storage/ACMFCVFE/article.html:text/html},
}

@article{brendel_learning_2020,
	title = {Learning to represent signals spike by spike},
	volume = {16},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007692},
	doi = {10.1371/journal.pcbi.1007692},
	abstract = {Networks based on coordinated spike coding can encode information with high efficiency in the spike trains of individual neurons. These networks exhibit single-neuron variability and tuning curves as typically observed in cortex, but paradoxically coincide with a precise, non-redundant spike-based population code. However, it has remained unclear whether the specific synaptic connectivities required in these networks can be learnt with local learning rules. Here, we show how to learn the required architecture. Using coding efficiency as an objective, we derive spike-timing-dependent learning rules for a recurrent neural network, and we provide exact solutions for the networks’ convergence to an optimal state. As a result, we deduce an entire network from its input distribution and a firing cost. After learning, basic biophysical quantities such as voltages, firing thresholds, excitation, inhibition, or spikes acquire precise functional interpretations.},
	language = {en},
	number = {3},
	urldate = {2022-09-20},
	journal = {PLOS Computational Biology},
	author = {Brendel, Wieland and Bourdoukan, Ralph and Vertechi, Pietro and Machens, Christian K. and Denève, Sophie},
	month = mar,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Action potentials, Coding mechanisms, Membrane potential, Neural networks, Neuronal tuning, Neurons, Signaling networks, Speech signal processing},
	pages = {e1007692},
	file = {Full Text PDF:/home/max/Zotero/storage/CZV96R6W/Brendel et al. - 2020 - Learning to represent signals spike by spike.pdf:application/pdf;Snapshot:/home/max/Zotero/storage/4QSKUIUN/article.html:text/html},
}
