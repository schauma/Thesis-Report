\chapter{<Theoretical Background>}
% \thispagestyle{fancy}
In this chapter, a detailed description about background of the degree project is presented together with related work. Discuss what is found useful and what is less useful. Use valid arguments.

Explain what and how prior work / prior research will be applied on or used in the degree project /work (described in this thesis). Explain why and what is not used in the degree project and give valid reasons for rejecting the work/research.

Use references!

\section{Use headings to break the text}
Do not use subtitles after each other without text in between the sections.

\section{Related Work}
You should probably keep a heading about the related work here even though the entire chapter basically only contains related work.

Here just what has been done for each of the headlines\\
Previous efforts were already made to control dynamic systems with \acp{SNN}.
\todi{List here also efforts with other concepts apart from Balanced Networks}




Neural networks in general
spiking neural networks and their differences and what they are better for.
neuron models, iwazishi neuron and maybe one more
mein neuron model und warum ich es ausgewaelt habe: einfach zu implementieren. Bereits fuer dynamische systeme verwendet,
Nachteile dieses modells.
Vlt vergleich mit einem anderen modell.
Ganz kurzer ausflug in die regelung von dynamischen systemen.


What is a neural network? -> not here ref a paper. kurze erkl'rung in der einfuerung
in der einfuhurng vlt auch hodgekin huxley erwaehen :)



\section{Dynamic systems}

\section{Neuron model}

\subsection{Biological Neuron model}
The most biologically accurate model of neuron spiking is the \ac{HH} model. The \ac{HH}-model considers the neuron with its ion channels. The membrane acts as a capacitance and the travelling ions in each ion channel contribute a current to the overall membrane potential. These ion gates are voltage dependent and are defined positive in direction out of the cell.\\
A particular ion channel for ion $X$ can be modelled as
\begin{equation}
	I_X= g_X \cdot (V-V_X)
\end{equation}
These currents are summed summed for the different ion channels in question, most commonly for Sodium, Potassium and a leak current. In reality there are a plethora of different channels and channel properties\footnote{See  \url{channelpedia.epfl.ch} for an extensive list}. The $V_X$ are the equilibrium potentials for each of the channels and can be computed using the Nernst equation \cite{johnston_foundations_1995}. \addref{Add a reference to a monography.}
\begin{equation}
	C \frac{dV}{dt} = g_{Na} \cdot (V-V_{Na}) + g_K \cdot (V-V_K) + g_l \cdot (V-V_l)
\end{equation}
Do model the voltage dependency of the ion channels, the conductances are described with gating variables, usually called $n$, $h$ and $g$ for Na-Activation, Na-Inactivation and K-activation respectively. One gating variable is set between $[0,1]$ and models the permeability of said gate. Multiple gates are used to fit to each ion channel in order to match experimental data and the model behaviour.\\
Gates have first order dynamics of the form
\begin{equation}
	\frac{dn}{dt} = \alpha_n(1-n) - \beta_n n
\end{equation}
for e.g the n gate. The other gates' dynamics are analogous. The functions $\alpha$ and $\beta$ are voltage but not time dependent. The discussion of initial values as well as functions for $\alpha_p,\ \beta_p\ \ p = (n,h,m)$ can be found in \cite{hodgkin_quantitative_1952} or \cite{johnston_foundations_1995}. The gates for each ion channel's conductance are found to be
\begin{equation}
	\begin{aligned}
	g_{Na} &= \bar{g}_{Na} n^4\\
	g_{K} &= \bar{g}_{K} m^3h\\
	\end{aligned}
\end{equation}
and give form to the final model
\begin{equation}\label{eq:HH}
	\begin{aligned}
	C\frac{dV}{dt} &= I(t) -\bar{g}_{Na} n^4(V-V_{Na}) - \bar{g}_{K} m^3h(V-V_{K}) -g_L(V-V_{L})\\
	\frac{dn}{dt} &= (1-n)\alpha_n(V) - \beta_n n (V)\\
	\frac{dm}{dt} &= (1-m)\alpha_m(V) - \beta_m m (V)\\
	\frac{dh}{dt} &= (1-h)\alpha_h(V) - \beta_h h (V)
	\end{aligned}
\end{equation}
We did not define a gate for the leak term as it is assumed constant.
\subsection{"IF and LIF"}
In contrast of the \ac{HH} model in \cref{eq:HH}, the simplest models of neurons are the \ac{IF} and \ac{LIF} models.\\
\paragraph{IF Neurons}
\ac{IF} Neurons, as the name implies, integrate the incoming current over time.
\begin{equation}
	\frac{d V(t)}{d t} = \frac{1}{C}I(t)
\end{equation}
The membrane voltage is governed by the incoming current spikes of connected neurons and the membrane capacitance. The neuron potential does not change without a change of input current and thus presents as a perfect integrator of the input.\\
\paragraph{\ac{LIF} Neurons}
In contrast to that the \ac{LIF} neuron contains a leak term on the RHS which brings the voltage back to its resting potential over time. The model can be expressed as
\begin{equation}
	\tau\frac{dV(t)}{dt} = -(V(t)-E_r) + RI(t),
\end{equation}
where $\tau = RC$ is the time constant the composed of the membrane resistance $R$ and the membrane capacitance $C$ and the resting potential $E_r$. In the absence of input $I(t)$ the voltage settles on the membrane potential $E_r$.\\
The input $I(t)$ encapsulates external inputs as well as a sum of Dirac functions indicating a spiking neuron
\begin{equation}
	I(t) = \sum_k \delta(t-t^k)
\end{equation}
\rewrite{This is not truly correct. Forgot weights, but at the same time only when there are more than 1 neuron}
and $t_k$ being the time of the $k$-th spike. When the membrane voltage exceeds the threshold potential $\bar{v}$, a spike is sent out by the neuron and the voltage sets back to its reset voltage $v_{res}$.
\subsection{Izhikevich Neuron}
While the above models deliver a useful and cheap simplification, they lack in accuracy. The Izhikevich model \cite{izhikevich_simple_2003} of the neuron tries be the of both worlds in terms of efficiency and accuracy. It is comprised of 2D ODEs with the membrane potential $v$ as
\begin{equation}
	\begin{aligned}
	\frac{d v}{dt} &= 0.04v^2 + 5v + 140 -u +I(t)\\
	\frac{d u}{dt} &= a(bv-u).
	\end{aligned}
\end{equation}
With the chosen factors, the neuron experiences a spike when $u\geq30 $mV, in which case the neuron resets to
\begin{equation}
\begin{aligned}
	u &\leftarrow u+d\\
	v&\leftarrow c
\end{aligned}
\end{equation}
The parameters describe $a$ scale of recovery, $b$ sensitivity, $c$ the reset potential of $v$ and $d$ the reset of variable $u$.\rewrite{Maybe shitty explanation, which could be extended on.} Depending on these parameters one can achieve different behaviours of the neuron e.g. regular spiking, fast spiking and low threshold spiking to name a few \cite{izhikevich_simple_2003}.

\section{Neural Networks}

\subsection{Biological Neural Network}

\subsection{Artificial Neural Networks}
 \todo{Make clear distinction between forward nns and ann. Bcs apparently they are not the same!}
\subsection{Spiking Neural Networks}
A spiking Neural network is one step closer to a biologic representation of a brain. Instead of conveying information using a gradient in conventional \ac{NN}s, information is propagated using discrete spikes of excitation, similar to biological neurons. Hereby one can distinguish between several ideas of implementation.

\subsection{Poisson-Networks}

\subsection{Liquid state machines}
\todi{write how the offline computing is pretty bad for brain things, but good for chess for example. The online computing is what the brain does and it is not yet as developed. add the TU graz paper to refs and some of it's references too, for example nr. 19}
One alternative method has been the use of \ac{LSM} or more general Reservoir computing.\\
The term Reservoir computing was introduced by Benjamin Schrauwen and describes a general group of recurrent network approach\cite{verstraeten_experimental_2007}.\\
The "reservoir" is a non-linear map from input to outputs that combines the input in various, even random ways. These contain but are not limited to sums, differences, multiplications, division and exponentiation. In general the output $\bmu{x}(t)$ is higher dimensional that the input $\bmu{v}(t)$, in order to allow for sufficient variety in the mapping. The output of the reservoir, which is usually treated as a black box, is fed in a linear decoder in order to retrieve the desired output signal.\\
\begin{figure}
	\centering
	\includesvg[scale= 0.15]{reservoir_computing}
	\caption{Abstract idea of Reservoir Computing. Adapted from \cite{cooper_liquid_2011}}
	\label{fig:reservoir_computing}
\end{figure}
The liquid can be made of any system that fulfils two properties.\\
\begin{itemize}
	\item Non-linear nodes of computation
	\item Fading memory
\end{itemize}
To these points it is usually set for the system to be time invariant\cite{cooper_liquid_2011}.
A reservoir can be a mathematical abstract formulation or physical object, e.g. a literal bucket of water \cite{tanaka_recent_2019}.\\
After the choice of "liquid" in the reservoir is fixed, its dynamics are not altered. Only the linear decoder is trained to return the desired decoded output. This is a considerable time saver since the training of recurrent networks is expensive. On the contrary the linear decoder can be learned relatively cheaply.\\
A reservoir computer is called a \ac{LSM} if one chooses a spiking neural network as the reservoir. The requirements mentioned above are fulfilled by the recurrent structure to retain information of the neurons and its non-linear spiking behaviour.\\
\acp{LSM} are capable of computing any dynamical system of any order of the form of
\begin{equation}
	z^{(n)} = G(z,z^{(1)},z^{(2)},\dots,z^{(n-1)}) + u
\end{equation}
given a sufficiently large liquid and a suitable feedback and decoder\cite{maass_computational_2004}. The systematic structure can be in \cref{fig:LSM_feedback}. The feedback $K(x,u)$ is a function of the dynamical system input $u(t)$ and the output $x(t)$. The result of $K(x,u)$ is fed back replaces the previous input $v(t)$ into the Liquid. The decoder $h(x)$ is not linear but can be simplified to be in a cost-performance trade-off when using a sufficiently large Liquid.\\
\begin{figure}[htbp]
	\centering
	\includesvg[scale= 0.15]{LSM_feedback2}
	\caption{Adding suitable feedback allows \acp{LSM} to be universal approximator. Adapted from \cite{maass_computational_2007}}
	\label{fig:LSM_feedback}
\end{figure}


\subsection{GLM}

\subsection{Balanced Networks}
Balanced networks differ from the previous approaches that they closely track excitation an inhibition. The derivation of its behaviour is adopted from \cite{boerlin_predictive_2013} and \cite{huang_optimizing_2017}.\\
We s¸
\rewrite{Add some more general stuff here!}

\todi{The derivation of the method used can be put to method or work/ here we can explain using only words and compare to the other methods and why we chose this one etc}
The derivation of the balanced spiking network follows the derivation found in \cite{boerlin_predictive_2013} and \cite{huang_dynamics_2019}.
The goal is to describe a dynamical system of the form
\begin{equation}\label{eq:x}
	\bmu{\dot{x}} = \bmu{Ax} + \bmu{c}(t)
\end{equation}
with $J$ state variables.
The estimating is done by leaky integration of spiking trains $\symbfup{o}(t)$ in
\begin{equation}\label{eq:x_hat}
	\bmu{\dot{\hat{x}}} = -\lambda_d \bmu{\hat{x}} + \symbfup{\Gamma} \bmu{o}(t).
\end{equation}
$\bmu{\Gamma}$ is a given Matrix of size $\mathbb{R}^{J\times N}$, $N$ being the number of neurons, with the different connection weights between the neurons. This matrix is given as initial and can be optimized by learning later.\\
In addition to the estimate $\bm{\hat{x}}$ we define a spiking rate variable $\bmu{r}$ following the dynamics of
\begin{equation}\label{eq:rate}
	\bmu{\dot{r}} = -\lambda_d\bmu{r} + \lambda_d \bmu{o}(t).
\end{equation}
The rate variable is connected to the state vector in the


The spikes are calculated by minimizing a cost function. A spike is fired if it minimizes the cost function that tracks the error between the true and estimated value over time
\begin{equation}
E(t)=\int_0^t \|\symbfup{x}(u)-\hat{\symbfup{x}}(u)\|_2^2 \ du.
\end{equation}

The cost function integrates the error between the estimate and the real dynamic variable as well as regularization terms.
\begin{equation}\label{eq:cost_func}
E(t)=\int_0^t \left(\|\symbfup{x}(u)-\hat{\symbfup{x}}(u)\|_2^2+\nu\|\symbfup{r}(u)\|_1+\mu\|\symbfup{r}(u)\|_2^2\right)d u
\end{equation}
These two regularization terms are added to discourage undesired behaviours.\\
The first was termed "ping-pong" effect and is described in the supplementary material of \cite{boerlin_predictive_2013}. Tp understand the issue, we imagine a minimal network consisting of 2 neurons with equal kernel but opposite sign. \rewrite{Write better the ping pong effect! Maybe later}\\

The second regularization comes into play when there are kernels with different magnitude. Kernels with small kernel magnitude reach their threshold sooner and therefore fire more frequently. In the extreme case, only small number of neurons fire rapidly while the majority remains idle. By penalizing the rate in the 2-norm it forces the network to spread the firing among the whole network.\\\rewrite{find the right place to explain that!}


The dynamic variable $\bmu{x}$ is tracked by firing spikes in when the defined "pseudo voltage" of a neuron surpasses its threshold. The voltage for each neuron is defined by
\begin{equation}\label{eq:voltage}
	V_i(t)=\bmu{\Gamma}^T(\bmu{x}(t)-\hat{\bmu{x}}(t))-\mu \lambda_d r_i(t)
\quad i  = 1\dots N.
\end{equation}
For negligible quadratic cost $\mu$ the voltage can be understood as measure of the error projected on $\bmu{\Gamma}_i$. The explicit derivation of the above equation is found in \cite{boerlin_predictive_2013} and will be adapted \rewrite{Where? Here, in the appendix of at all?}. The voltage definition and the threshold definition
\begin{equation}
	T_i=\frac{\nu \lambda_d+\mu \lambda_d^2+\left\|\boldsymbol{\bmu{\Gamma}}_i\right\|^2}{2}
\end{equation}
result from integrating the cost function \cref{eq:cost_func} over time step $\epsilon$. Then the condition described earlier fires a spike if the cost gets lowered. If there is no spike fired, the rate and estimated state variable in \cref{eq:x_hat} and \cref{eq:rate} respectively behave as
\begin{equation}
	\begin{aligned}
		\bmu{\dot{\hat{x}}} &= -\lambda_d \bmu{\hat{x}}\\
		\bmu{\dot{r}} &= -\lambda_d\bmu{r}
	\end{aligned}
\end{equation}
and therefore decay exponentially with $e^{-\lambda_d t}$.\\
If a spike is fired, the inhomogeneous solution is found by variation of constants in \cref{eq:rate} to
\begin{equation}
\begin{aligned}
	r_i^h &= c_i(t)e^{-\lambda_d t}\\
	c_i'(t) e^{-\lambda_d t} - c_i(t)\lambda_d e^{-\lambda_d t}&= -\lambda_d c_i(t)e^{-\lambda_d t} + \delta(t- t_i^k)\\
	c_i'(t) &= \delta(t- t_i^k) e^{\lambda_d t}\\
	c_i(t) &=  e^{\lambda_d t_i^k} \bm{H}(t-t_i^k)
\end{aligned}
\end{equation}
\rewrite{explain notation of spike time constant with i and k}
where $\bm{H}(t)$ denotes the Heaviside step function. It can been seen that at the time of firing the spike adds a decaying exponential to the rate variable. Similarly it adds a column of the previously defined connection matrix $\bm{\Gamma}$ to the state vector. Thus we can now compare the effects on cost function \cref{eq:cost_func} and compare its impact. The integral is approximated by a greedy optimization method such that for very small time steps $\epsilon$ the exponential decays $e^{-\lambda_d t - t_i^k}\approx 1$. The greedy optimization is necessary since the unpredictable firing due to noise makes it impossible to predict future spikes.\rewrite{Remember that i read somewhere that the noise is necessary. Maybe mention that here too. And find the reference}. After this step the rewriting the terms and using the defintions of the voltage and threshold we arrive at the critera to spike when
\begin{equation}\label{eq:condition}
	V_i> T_i \quad i = 1\dots N
\end{equation}
\subsubsection{Neuron Voltage}
As mentioned above, a neuron spikes if it meets the condition \cref{eq:condition}. But so far we skipped over the dynamics how neuron voltage evolves over time.
We start by defining the left pseudo-inverse of our output matrix $\bmu{\Gamma}$ \todi{find a coherent name for the matrix}
\begin{equation}
	\bmu{L} = \left(\bmu{\Gamma}\bmu{\Gamma}^T\right)^{-1}\bmu{\Gamma}
\end{equation}
such that $\bmu{L}\bmu{\Gamma}^T = \bmu{I}$.\\
Next we take the derivative of \cref{eq:voltage} and arrive at
\begin{equation}\label{eq:voltage_dt}
	\bmu{\dot{V}}(t)=\bmu{\Gamma}^T\left(\bmu{\dot{x}}(t)-\dot{\hat{\bmu{x}}}(t)\right)-\mu \lambda_d \bmu{\dot{r}}(t).
\end{equation}
We now use the pseudo-inverse to rewrite the voltage equation \cref{eq:voltage} as
\begin{equation}\label{eq:voltage_2}
\begin{aligned}
	\bmu{V}(t)&=\bmu{\Gamma}^T(\bmu{x}(t)-\hat{\bmu{x}}(t))-\mu \lambda_d \bmu{r}(t)\\
	\bmu{L}\bmu{V}(t)&=(\bmu{x}(t)-\hat{\bmu{x}}(t))-\mu \lambda_d \bmu{L}\bmu{r}(t)\\
\end{aligned}
\end{equation}

We now replace the derivative terms in \cref{eq:voltage_dt} with their respective equations \cref{eq:x} to \cref{eq:rate}. Lastly we set





\subsection{Learning: SGD and STDP}
Key to give any \ac{NN} the ability to solve a task, it is integral to learn/train the network. The adaption of synapse weights is necessary to accomplish any functionality based on the underlying data\addref{Put this reference in and say its is copied partly from them}\cite{zheng_introductory_2022}. There are various ways to train a network. The most fundamental distinction can be made between supervised, unsupervised and reinforcement learning rules.
One needs to remember that \acp{ANN} and \acp{SNN} require completely different learning algorithms because of their different transport of information.\\
For a review

\subsubsection{Supervised Learning methods}
Gradient based methods require differentiability and therefore continuity, thus are only applicable for \acp{ANN}.\\
\todi{Explain gradient methods. The derivative of the weights and biases is used for the derivative of the cost function. Efficient methods for building the derivative exists. With reference!}

\subsubsection{Unsupervised Learning methods}
STDP
\subsubsection{Reinforcement learning}



Here explain the conpects for each of the NNs\\
Give references for the STDP variances\\
