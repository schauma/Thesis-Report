\chapter{<Theoretical Background>}
% \thispagestyle{fancy}
In this chapter, a detailed description about background of the degree project is presented together with related work. Discuss what is found useful and what is less useful. Use valid arguments.

Explain what and how prior work / prior research will be applied on or used in the degree project /work (described in this thesis). Explain why and what is not used in the degree project and give valid reasons for rejecting the work/research.

Use references!

\section{Use headings to break the text}
Do not use subtitles after each other without text in between the sections.

\section{Related Work}
You should probably keep a heading about the related work here even though the entire chapter basically only contains related work.

Here just what has been done for each of the headlines\\


Neural networks in general
spiking neural networks and their differences and what they are better for.
neuron models, iwazishi neuron and maybe one more
mein neuron model und warum ich es ausgewaelt habe: einfach zu implementieren. Bereits fuer dynamische systeme verwendet,
Nachteile dieses modells.
Vlt vergleich mit einem anderen modell.
Ganz kurzer ausflug in die regelung von dynamischen systemen.


What is a neural network? -> not here ref a paper. kurze erkl'rung in der einfuerung
in der einfuhurng vlt auch hodgekin huxley erwaehen :)



\section{Dynamic systems}

\section{Neuron model}

\subsection{Biological Neuron model}
The most biologically accurate model of neuron spiking is the \ac{HH} model. The \ac{HH}-model considers the neuron with its ion channels. The membrane acts as a capacitance and the travelling ions in each ion channel contribute a current to the overall membrane potential. These ion gates are voltage dependent and are defined positive in direction out of the cell.\\
A particular ion channel for ion $X$ can be modelled as
\begin{equation}
	I_X= g_X \cdot (V-V_X)
\end{equation}
These currents are summed summed for the different ion channels in question, most commonly for Sodium, Potassium and a leak current. In reality there are a plethora of different channels and channel properties\footnote{See  \url{channelpedia.epfl.ch} for an extensive list}. The $V_X$ are the equilibrium potentials for each of the channels and can be computed using the Nernst equation \cite{johnston_foundations_1995}. \addref{Add a reference to a monography.}
\begin{equation}
	C \frac{dV}{dt} = g_{Na} \cdot (V-V_{Na}) + g_K \cdot (V-V_K) + g_l \cdot (V-V_l)
\end{equation}
Do model the voltage dependency of the ion channels, the conductances are described with gating variables, usually called $n$, $h$ and $g$ for Na-Activation, Na-Inactivation and K-activation respectively. One gating variable is set between $[0,1]$ and models the permeability of said gate. Multiple gates are used to fit to each ion channel in order to match experimental data and the model behaviour.\\
Gates have first order dynamics of the form
\begin{equation}
	\frac{dn}{dt} = \alpha_n(1-n) - \beta_n n
\end{equation}
for e.g the n gate. The other gates' dynamics are analogous. The functions $\alpha$ and $\beta$ are voltage but not time dependent. The discussion of initial values as well as functions for $\alpha_p,\ \beta_p\ \ p = (n,h,m)$ can be found in \cite{hodgkin_quantitative_1952} or \cite{johnston_foundations_1995}. The gates for each ion channel's conductance are found to be
\begin{equation}
	\begin{aligned}
	g_{Na} &= \bar{g}_{Na} n^4\\
	g_{K} &= \bar{g}_{K} m^3h\\
	\end{aligned}
\end{equation}
and give form to the final model
\begin{equation}\label{eq:HH}
	\begin{aligned}
	C\frac{dV}{dt} &= I(t) -\bar{g}_{Na} n^4(V-V_{Na}) - \bar{g}_{K} m^3h(V-V_{K}) -g_L(V-V_{L})\\
	\frac{dn}{dt} &= (1-n)\alpha_n(V) - \beta_n n (V)\\
	\frac{dm}{dt} &= (1-m)\alpha_m(V) - \beta_m m (V)\\
	\frac{dh}{dt} &= (1-h)\alpha_h(V) - \beta_h h (V)
	\end{aligned}
\end{equation}
We did not define a gate for the leak term as it is assumed constant.
\subsection{"IF and LIF"}
In contrast of the \ac{HH} model in \cref{eq:HH}, the simplest models of neurons are the \ac{IF} and \ac{LIF} models.\\
\paragraph{IF Neurons}
\ac{IF} Neurons, as the name implies, integrate the incoming current over time.
\begin{equation}
	\frac{d V(t)}{d t} = \frac{1}{C}I(t)
\end{equation}
The membrane voltage is governed by the incoming current spikes of connected neurons and the membrane capacitance. The neuron potential does not change without a change of input current and thus presents as a perfect integrator of the input.\\
\paragraph{\ac{LIF} Neurons}
In contrast to that the \ac{LIF} neuron contains a leak term on the RHS which brings the voltage back to its resting potential over time. The model can be expressed as
\begin{equation}
	\tau\frac{dV(t)}{dt} = -(V(t)-E_r) + RI(t),
\end{equation}
where $\tau = RC$ is the time constant the composed of the membrane resistance $R$ and the membrane capacitance $C$ and the resting potential $E_r$. In the absence of input $I(t)$ the voltage settles on the membrane potential $E_r$.\\
The input $I(t)$ encapsulates external inputs as well as a sum of Dirac functions indicating a spiking neuron
\begin{equation}
	I(t) = \sum_k \delta(t-t^k)
\end{equation}
\rewrite{This is not truly correct. Forgot weights, but at the same time only when there are more than 1 neuron}
and $t_k$ being the time of the $k$-th spike. When the membrane voltage exceeds the threshold potential $\bar{v}$, a spike is sent out by the neuron and the voltage sets back to its reset voltage $v_{res}$.
\subsection{Izhikevich Neuron}
While the above models deliver a useful and cheap simplification, they lack in accuracy. The Izhikevich model \cite{izhikevich_simple_2003} of the neuron tries be the of both worlds in terms of efficiency and accuracy. It is comprised of 2D ODEs with the membrane potential $v$ as
\begin{equation}
	\begin{aligned}
	\frac{d v}{dt} &= 0.04v^2 + 5v + 140 -u +I(t)\\
	\frac{d u}{dt} &= a(bv-u).
	\end{aligned}
\end{equation}
With the chosen factors, the neuron experiences a spike when $u\geq30 $mV, in which case the neuron resets to
\begin{equation}
\begin{aligned}
	u &\leftarrow u+d\\
	v&\leftarrow c
\end{aligned}
\end{equation}
The parameters describe $a$ scale of recovery, $b$ sensitivity, $c$ the reset potential of $v$ and $d$ the reset of variable $u$.\rewrite{Maybe shitty explanation, which could be extended on.} Depending on these parameters one can achieve different behaviours of the neuron e.g. regular spiking, fast spiking and low threshold spiking to name a few \cite{izhikevich_simple_2003}.

\section{Neural Networks}

\subsection{Biological Neural Network}

\subsection{Artificial Neural Networks}

\subsection{Spiking Neural Networks}
A spiking Neural network is one step closer to a biologic representation of a brain. Instead of conveying information using a gradient in conventional \ac{NN}s, information is propagated using discrete spikes of excitation, similar to biological neurons. Hereby one can distinguish between several ideas of implementation.

\subsection{Poisson-Networks}

\subsection{Liquid state machines}

\subsection{GLM}

\subsection{Balanced Networks}
Balanced networks differ from the previous approaches that they closely track excitation an inhibition. The derivation of its behaviour is adopted from \cite{boerlin_predictive_2013} and \cite{huang_optimizing_2017}.\\
We s

\subsection{Learning: SGD and STDP}
Key to give any \ac{NN} a function, it is integral to learn/train the network. The adaption of synapse weights is necessary to accomplish any functionality. There are various ways to train a network. The most fundamental distinction can be made between supervised, unsupervised and reinforcement learning rules.
\todi{Add the explanation for unsupervised and supervised and reinforcement}.
One needs to remember that \acp{ANN} and \acp{SNN} require completely different learning algorithms because of their different transport of information.
\subsubsection{Unsupervised Learning}


\subsubsection{Gradient methods}
Gradient based methods require differentiability and therefore continuity, thus are only applicable for \acp{ANN}.\\
 \todi{Explain gradient methods. The derivative of the weights and biases is used for the derivative of the cost function. Efficient methods for building the derivative exists. With reference!}
\subsubsection{STDP}

Here explain the conpects for each of the NNs\\
Give references for the STDP variances\\
test\\
