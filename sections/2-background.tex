\chapter{<Theoretical Background>}
% \thispagestyle{fancy}
In this chapter, a detailed description about background of the degree project is presented together with related work. Discuss what is found useful and what is less useful. Use valid arguments.

Explain what and how prior work / prior research will be applied on or used in the degree project /work (described in this thesis). Explain why and what is not used in the degree project and give valid reasons for rejecting the work/research.

Use references!

\section{Use headings to break the text}
Do not use subtitles after each other without text in between the sections.

\section{Related Work}
You should probably keep a heading about the related work here even though the entire chapter basically only contains related work.

Here just what has been done for each of the headlines\\
Previous efforts were already made to control dynamic systems with \acp{SNN}.
\todi{List here also efforts with other concepts apart from Balanced Networks}




Neural networks in general
spiking neural networks and their differences and what they are better for.
neuron models, iwazishi neuron and maybe one more
mein neuron model und warum ich es ausgewaelt habe: einfach zu implementieren. Bereits fuer dynamische systeme verwendet,
Nachteile dieses modells.
Vlt vergleich mit einem anderen modell.
Ganz kurzer ausflug in die regelung von dynamischen systemen.


What is a neural network? -> not here ref a paper. kurze erkl'rung in der einfuerung
in der einfuhurng vlt auch hodgekin huxley erwaehen :)



\section{Dynamic systems}
\section{Autoencoder}
An autoencoder is a type of neural network for learning a representation of its input. It consists of an encoder and decoder function $z =f(x)$ \& $\hat{x} = g(z)$. The encoder function from the input space, e.g $\mathbb{R}^n$, to a encoded space $\mathcal{C}$. The decoder is then decoding the data from $\mathcal{Z}$ back to $\mathbb{R}^n$. The goal is that the representation is as accurate as possible. This is easy in case the if $\mathcal{Z}$ is equal or larger than the input space. Then every possible input can be encoded by its own value as
\begin{equation}
\begin{aligned}
 	z = f(x) &= x\\
 	\hat{x} = g(z) &= z = x
\end{aligned}
\end{equation}
which is not useful. $\mathcal{Z}$ has to many DOF and can "memorize" each input. In most cases however $\mathcal{Z}$ is constrained that the autoencoder has to find the relevant properties of the input. This is often done by reducing the dimension if $\mathcal{Z}$ or by regularization. Regularization is added to the Loss
\begin{equation}
	L(x,\hat{x}) + C(z)
\end{equation}
where L can be e.g. MSE and the regularization term $C$ can enforce sparsity or other properties\cite{goodfellow_deep_2016}.

\section{Neuron model}

\subsection{Biological Neuron model}
\todi{there are more than the HH now. Check wiki of HH model}
The most biologically accurate model of neuron spiking is the \ac{HH} model. The \ac{HH}-model considers the neuron with its ion channels. The membrane acts as a capacitance and the travelling ions in each ion channel contribute a current to the overall membrane potential. These ion gates are voltage dependent and are defined positive in direction out of the cell.\\
A particular ion channel for ion $X$ can be modelled as
\begin{equation}
	I_X= g_X \cdot (V-V_X)
\end{equation}
These currents are summed summed for the different ion channels in question, most commonly for Sodium, Potassium and a leak current. In reality there are a plethora of different channels and channel properties\footnote{See  \url{channelpedia.epfl.ch} for an extensive list}. The $V_X$ are the equilibrium potentials for each of the channels and can be computed using the Nernst equation \cite{johnston_foundations_1995}. \addref{Add a reference to a monography.}
\begin{equation}
	C \frac{dV}{dt} = g_{Na} \cdot (V-V_{Na}) + g_K \cdot (V-V_K) + g_l \cdot (V-V_l)
\end{equation}
Do model the voltage dependency of the ion channels, the conductances are described with gating variables, usually called $n$, $h$ and $g$ for Na-Activation, Na-Inactivation and K-activation respectively. One gating variable is set between $[0,1]$ and models the permeability of said gate. Multiple gates are used to fit to each ion channel in order to match experimental data and the model behaviour.\\
Gates have first order dynamics of the form
\begin{equation}
	\frac{dn}{dt} = \alpha_n(1-n) - \beta_n n
\end{equation}
for e.g the n gate. The other gates' dynamics are analogous. The functions $\alpha$ and $\beta$ are voltage but not time dependent. The discussion of initial values as well as functions for $\alpha_p,\ \beta_p\ \ p = (n,h,m)$ can be found in \cite{hodgkin_quantitative_1952} or \cite{johnston_foundations_1995}. The gates for each ion channel's conductance are found to be
\begin{equation}
	\begin{aligned}
	g_{Na} &= \bar{g}_{Na} n^4\\
	g_{K} &= \bar{g}_{K} m^3h\\
	\end{aligned}
\end{equation}
and give form to the final model
\begin{equation}\label{eq:HH}
	\begin{aligned}
	C\frac{dV}{dt} &= I(t) -\bar{g}_{Na} n^4(V-V_{Na}) - \bar{g}_{K} m^3h(V-V_{K}) -g_L(V-V_{L})\\
	\frac{dn}{dt} &= (1-n)\alpha_n(V) - \beta_n n (V)\\
	\frac{dm}{dt} &= (1-m)\alpha_m(V) - \beta_m m (V)\\
	\frac{dh}{dt} &= (1-h)\alpha_h(V) - \beta_h h (V)
	\end{aligned}
\end{equation}
We did not define a gate for the leak term as it is assumed constant.
\subsection{"IF and LIF"}
In contrast of the \ac{HH} model in \cref{eq:HH}, the simplest models of neurons are the \ac{IF} and \ac{LIF} models.\\
\paragraph{IF Neurons}
\ac{IF} Neurons, as the name implies, integrate the incoming current over time.
\begin{equation}
	\frac{d V(t)}{d t} = \frac{1}{C}I(t)
\end{equation}
The membrane voltage is governed by the incoming current spikes of connected neurons and the membrane capacitance. The neuron potential does not change without a change of input current and thus presents as a perfect integrator of the input.\\
\paragraph{\ac{LIF} Neurons}
In contrast to that the \ac{LIF} neuron contains a leak term on the RHS which brings the voltage back to its resting potential over time. The model can be expressed as
\begin{equation}
	\tau\frac{dV(t)}{dt} = -(V(t)-E_r) + RI(t),
\end{equation}
where $\tau = RC$ is the time constant the composed of the membrane resistance $R$ and the membrane capacitance $C$ and the resting potential $E_r$. In the absence of input $I(t)$ the voltage settles on the membrane potential $E_r$.\\
The input $I(t)$ encapsulates external inputs as well as a sum of Dirac functions indicating a spiking neuron
\begin{equation}
	I(t) = \sum_k \delta(t-t^k)
\end{equation}
\rewrite{This is not truly correct. Forgot weights, but at the same time only when there are more than 1 neuron}
and $t_k$ being the time of the $k$-th spike. When the membrane voltage exceeds the threshold potential $\bar{v}$, a spike is sent out by the neuron and the voltage sets back to its reset voltage $v_{res}$.
\subsection{Izhikevich Neuron}
While the above models deliver a useful and cheap simplification, they lack in accuracy. The Izhikevich model \cite{izhikevich_simple_2003} of the neuron tries be the of both worlds in terms of efficiency and accuracy. It is comprised of 2D ODEs with the membrane potential $v$ as
\begin{equation}
	\begin{aligned}
	\frac{d v}{dt} &= 0.04v^2 + 5v + 140 -u +I(t)\\
	\frac{d u}{dt} &= a(bv-u).
	\end{aligned}
\end{equation}
With the chosen factors, the neuron experiences a spike when $u\geq30 $mV, in which case the neuron resets to
\begin{equation}
\begin{aligned}
	u &\leftarrow u+d\\
	v&\leftarrow c
\end{aligned}
\end{equation}
The parameters describe $a$ scale of recovery, $b$ sensitivity, $c$ the reset potential of $v$ and $d$ the reset of variable $u$.\rewrite{Maybe shitty explanation, which could be extended on.} Depending on these parameters one can achieve different behaviours of the neuron e.g. regular spiking, fast spiking and low threshold spiking to name a few \cite{izhikevich_simple_2003}.

\section{Neural Networks}

\subsection{Biological Neural Network}

\subsection{Artificial Neural Networks}
 \todo{Make clear distinction between forward nns and ann. Bcs apparently they are not the same!}
\subsection{Spiking Neural Networks}
A spiking Neural network is one step closer to a biologic representation of a brain. Instead of conveying information using a gradient in conventional \ac{NN}s, information is propagated using discrete spikes of excitation, similar to biological neurons. Hereby one can distinguish between several ideas of implementation.
\rewrite{The main difference is the motion of time}

\subsection{Poisson Networks}
Poisson networks are built around the idea that information is encoded in the firing rate of a neuron. The precise timing of a spike is essentially meaningless\cite{brette_philosophy_2015}. This makes a strong contrast to the approach chosen in this paper, where every spike is timed exactly to minimize a cost function.\rewrite{Maaybe add that our approach does not rule rate out completely.}
The encoding of a value, e.g. four, is set by endowing the input neurons with a Poisson point process with a suitable encoding rate $r_i$\cite{deneve_efficient_2016}.\\
One typically uses probabilistic stimuli because observations in the spiking of the human brain do are different in a trial by trial basis.\\
Input spikes are travelling through the recurrent network with weighted connections. The decoding is done by counting the spikes of output neurons over a certain time window. The time window plays a crucial rule in the decoding. If it is set smaller, spatio temporal patterns can be captured which can convey information about the input. Equally the sensitivity to noise becomes greater. If the time window is set to large, the firing patterns are lost though the impact of random spikes is reduced.\\
\todo{Write that the error scales pretty badly with the squareroot and therefore we need a lot of spikes to get certain precision. I do not understand how and why. For regular timed spikes we the error scales linearly so we need many fewer spikes. But mention the CV value and explain it. Ref are the boerlin and nature paper. With that explain the pro and con like noise resistance bcs of many spikes and the inefficiency of the rate encoding.}
Theoretically using a lot of spikes is unproblematic and with large spike counts neuromorphic hardware is still much more energy efficient than deep neural networks if one seeks to deploy it. \addref{Maybe I can find a stat on how much more efficient neuromorphic hardware really is.}\rewrite{sounds a bit bad}

The connection weights are subject to change over the learning/training period\cite{almomani_comparative_2019}.\\
This approach however has some conceptual problems. Firstly, this approach has the problem that responses are limited by the time window the spikes are counted\cite{andrew_spiking_2003}. This means that the rate decoding is to slow to capture the fast travelling information and another needs to be another faster way to transmit information. However it has been shown that the firing rate does convey information about the stimuli's magnitude \cite{adrian_impulses_1926}.\\
The second problem is that due to the Poisson process one needs more spikes to represent an average firing rate. An action potential consumes a lot of the cells energy\cite{attwell_energy_2001}, thus making it unfeasible to use a large number of spikes if one tries to model the brain. Evolution has found a better way to transmit information.


Although the above mentioned problems, rate encoded \acp{SNN} have seen interest by research. A big hurdle of deploying \acp{SNN} is the lack of performant learning algorithms. For this there efforts have been made to train recurrent or convolutional \acp{ANN} using backpropagation and afterwards convert the trained network to a \ac{SNN}\cite{pfeiffer_deep_2018} using rate encoding\cite{diehl_conversion_2016}\cite{diehl_fast-classifying_2015}.
\rewrite{Maybe find a reference that the power consumption is really low even though the use rate based encoding}

\rewrite{Say that the CV(explain what it is :sigma/mu and what it says) value is shit so you you need a ton of spikes. Then say that it has some use and some perfomrance when you transmit from an ann and move it to a snn with neuromophic hardware. USe the papers from the nature paper forward  to the right.}
\subsection{Liquid state machines}
\todi{write how the offline computing is pretty bad for brain things, but good for chess for example. The online computing is what the brain does and it is not yet as developed.}
One alternative method has been the use of \ac{LSM} or more general Reservoir computing.\\
The term Reservoir computing was introduced by Benjamin Schrauwen and describes a general group of recurrent network approach\cite{verstraeten_experimental_2007}.\\
The "reservoir" is a non-linear map from input to outputs that combines the input in various, even random ways. These contain but are not limited to sums, differences, multiplications, division and exponentiation. In general the output $\bmu{x}(t)$ is higher dimensional that the input $\bmu{v}(t)$, in order to allow for sufficient variety in the mapping. The output of the reservoir, which is usually treated as a black box, is fed in a linear decoder in order to retrieve the desired output signal.\\
\begin{figure}
	\centering
	\includesvg[scale= 0.15]{reservoir_computing}
	\caption{Abstract idea of Reservoir Computing. Adapted from \cite{cooper_liquid_2011}}
	\label{fig:reservoir_computing}
\end{figure}
The liquid can be made of any system that fulfils two properties.\\
\begin{itemize}
	\item Non-linear nodes of computation
	\item Fading memory
\end{itemize}
To these points it is usually set for the system to be time invariant\cite{cooper_liquid_2011}.
A reservoir can be a mathematical abstract formulation or physical object, e.g. a literal bucket of water \cite{tanaka_recent_2019}.\\
After the choice of "liquid" in the reservoir is fixed, its dynamics are not altered. Only the linear decoder is trained to return the desired decoded output. This is a considerable time saver since the training of recurrent networks is expensive. On the contrary the linear decoder can be learned relatively cheaply.\\
A reservoir computer is called a \ac{LSM} if one chooses a spiking neural network as the reservoir. The requirements mentioned above are fulfilled by the recurrent structure to retain information of the neurons and its non-linear spiking behaviour.\\
\acp{LSM} are capable of computing any dynamical system of any order of the form of
\begin{equation}
	z^{(n)} = G(z,z^{(1)},z^{(2)},\dots,z^{(n-1)}) + u
\end{equation}
given a sufficiently large liquid and a suitable feedback and decoder\cite{maass_computational_2004} and have been used for speech recognition\cite{jin_performance_2017}\cite{zhang_digital_2015}. The systematic structure can be in \cref{fig:LSM_feedback}. The feedback $K(x,u)$ is a function of the dynamical system input $u(t)$ and the output $x(t)$. The result of $K(x,u)$ is fed back replaces the previous input $v(t)$ into the Liquid. The decoder $h(x)$ is not linear but can be simplified to be in a cost-performance trade-off when using a sufficiently large Liquid.\\
\begin{figure}[htbp]
	\centering
	\includesvg[scale= 0.15]{LSM_feedback2}
	\caption{Adding suitable feedback allows \acp{LSM} to be universal approximator. Adapted from \cite{maass_computational_2007}}
	\label{fig:LSM_feedback}
\end{figure}

\subsection{Balanced Networks}
The idea of tightly balanced spiking networks was first proposed by Boerlin et al.\cite{boerlin_predictive_2013}. It uses predictive coding in combination with spikes to simulate arbitrary linear systems.
The technical derivation will be described in chapter \rewrite{Add the ref to the chapter}. The approach defines a cost function measuring the networks' accuracy in addition with regularization terms that moderates the spiking behaviour. Using a greedy algorithm this cost function determines the voltage threshold and therefore the neurons' spiking behaviour.\\
For each neuron voltage can be understood as a projection of the global system error to a local error.\\
Therefore the spiking rule is set to fire if the Voltage of a neuron becomes to large in order to reset the neuron voltage and reduce part of the system error.


Balanced networks differ from the previous rate encoding in that excitation and inhibition is closely tracked. In rate encoded networks both inhibitory and excitatory spikes are received by a single neuron. An change of the variable is then governed by which type dominates. Here a rate coding is also used, however in combination with instantaneous decoding\cite{johnson_minimum-error_2016}.


The derivation of its behaviour is adopted from \cite{boerlin_predictive_2013},\cite{huang_spiking_2019} and \cite{huang_optimizing_2017}.
\rewrite{Add some more general stuff here!}

\todi{The derivation of the method used can be put to method or work/ here we can explain using only words and compare to the other methods and why we chose this one etc}
\todi{Reference to method for the derivation}
\subsection{Learning: SGD and STDP}
STDP\\
Gradient descent\\
Hebbian\\
maybe?

Key to give any \ac{NN} the ability to solve a task, it is integral to learn/train the network. The adaption of synapse weights is necessary to accomplish any functionality based on the underlying data\addref{Put this reference in and say its is copied partly from them}\cite{zheng_introductory_2022}. There are various ways to train a network. The most fundamental distinction can be made between supervised, unsupervised and reinforcement learning rules.
One needs to remember that \acp{ANN} and \acp{SNN} require completely different learning algorithms because of their different transport of information.\\
For a review

\subsubsection{Supervised Learning methods}
Gradient based methods require differentiability and therefore continuity, thus are only applicable for \acp{ANN}.\\
\todi{Explain gradient methods. The derivative of the weights and biases is used for the derivative of the cost function. Efficient methods for building the derivative exists. With reference!}

\subsubsection{Unsupervised Learning methods}
STDP
\subsubsection{Reinforcement learning}



Here explain the conpects for each of the NNs\\
Give references for the STDP variances\\
