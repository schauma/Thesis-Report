\chapter{Introduction}

The human brain is a brilliant computing unit comprised of around 86 billion neurons\cite{azevedo_equal_2009}. Each of these neurons can have thousands of connections to other neurons. Between these connections, information travels through the network as electrical impulses that interact with the neuron's own electrical potential. With this network, the human brain is capable of performing vastly different and complex tasks. Machines and robots surpass humans in raw computing power by several orders of magnitude, yet many tasks are next to impossible to solve by machines and classical algorithms alone. Moreover, many machine implementations lack the speed, precision, or flexibility of their human counterparts.

Researchers have sought to address this by mimicking the brain's internal network structure to solve problems deemed unsuitable for classic algorithms. \acp{ANN} have shown a great success in previously hard-to-solve problems. However, the classical \acp{ANN} still struggle in the context of control. Where the highly abstract \acp{ANN} reach there limits, a more biologically plausible network type can overcome this obstacle. \acp{SNN} can provide a powerful framework to solve complex problems. Furthermore, with newer, more biologically inspired networks, we are able to solve a broader range of problems. The concept of \acp{SNN} will be described in detail in a later section. By Using \acp{SNN}, we set out to design such a network in order to control a linear system.

\section{Background}\label{sec:background}

The most common neural network architecture for \acp{ANN} is the feed-forward network.
In these networks, information travels only in one direction and is not propagated by spikes but gradients of activation, usually set in the range $[0,1]$ or $[-1,1]$.
Feed-Forward \acp{ANN} have made impressive progress in the fields of image recognition, autonomic driving, medical diagnosis\cite{patel_applications_2007} or  \ac{NLP} (using Transformers\cite{vaswani_attention_2017}). While this abstract representation brings advantages e.g in modelling and implementation, it also lacks some key features of the human brain. Due to the information travelling only towards the output, feed-forward networks cannot build a memory or easily process temporal data. Recurrent models exist, which allow for memory \cite{hutchison_biologically_2004} and sequential data input but loose some of the advantages compared to the Feed-Forward networks due to their increased complexity.\\

A third generation\cite{maass_networks_1997} of network architectures has risen, aiming to be even more biologically plausible. Inspired by nature, they implement spiking behaviour and recurrence found in the human brain. This newer form of \ac{SNN} is as powerful as the classic feed-forward but is better suited for temporal data encountered in control. While state-of-the-art Feed-Forward networks still outperform \acp{SNN}\footnote{Most benchmarks are based on static information e.g. images, which are adapted to \acp{SNN} and therefore do not allow a perfectly fair comparison.}, in some cases, modern \acp{SNN} are on par\cite{lee_training_2016} or more performant, with previous feed-forward implementations consuming more energy.

%\input{tables/sample-table}

\section{Problem}
Conventional Feed-Forward neural networks are not designed to work with temporal data; they are static input-output machines. While this makes sense in the context of many tasks, it simultaneously limits the power of these networks. There are workarounds to handle temporal data, such as sampling previous values back into the network (used in time series forecasting \cite{tang_feedforward_1993,yang_cascade_2022,uncini_audio_2003}) or by quantizing the whole input if the entire time horizon is available, as with recorded audio data.\\
Instead of these workarounds, \acp{RNN} are often proposed for such tasks. However, \acp{RNN} face challenges during training with back-propagation\cite{bengio_learning_1994}. For \acp{RNN} and deep Feed-Forward networks gradients used in the back-propagation algorithm can either explode or vanish. Different methods have been proposed to address this problem, such as batch normalization\cite{ioffe_batch_2015}, using alternative activation functions (ReLU)\cite{nair_rectified_2010}, or gradient clipping\cite{pascanu_difficulty_2013}, to name a few. Specifically for recurrent models, different architectures have been suggested, with the \ac{LSTM} cell \cite{hochreiter_long_1997} being prominent and successful in various applications\cite{mayer_system_2006, sak_long_2014, li_constructing_2015}.\\

Yet, these recurrent designs are not a plausible representation of biological networks. \acp{RNN} still operate on a continuous range of values instead of discrete spikes. Utilizing this continuity, they are trained with the biologically implausible global learning rules, such as the Back-Propagation algorithm. Furthermore, \acp{SNN} come with the added benefit of consuming less power. Usually, deep \acp{ANN} are run on \acp{GPU}, especially for training, where energy consumption can exceed 400W for modern chips\footnote{e.g. a NVidia RTX 4090}. In contrast, the brain is estimated to only consume about
20W \cite{clarke_circulation_1999} for its immense computing capacity. Accompanying \acp{SNN} with neuromorphic hardware can yield another boost in efficiency, with processors' energy consumption in the pJ per \ac{SOP}\cite{indiveri_importance_2019}, offering significant power savings.


\section{Goal}\label{sec:goal}
The goal of this project is to create a \ac{SNN} capable of controlling any given \ac{LTI} system. Furthermore, the \ac{NN} should be robust against failing neurons or connections. As an additional constraint, the objective is to achieve this goal using biologically tractable methods as much as possible.
To mimic the brain's learning, we aim to employ local training rules that are biologically plausible.\\
Achieving optimality is an ideal, although it is often unclear if this is possible. Even in highly researched \acp{ANN} this is typically a challenging condition, as conventional \acp{NN} using \ac{GD} only guarantee a local minimum.\\
Furthermore, in nature, the brain does not offer separate between training and trial periods. The brain self-modulates its learning online, meaning that the network is expected to improve on itself as it working the task at hand.\\
Lastly, adjusting neural networks to a specific task usually requires manual tuning of hyperparameters. The goal here is to automate as much of the process as possible, allowing the the network to find acceptable solutions given the task at hand, independent of the given control command or size of the system, without problem specific adjustments of hyper-parameters.\\
For the \ac{SNN} itself, we aim to find a balance between the biological plausibility and performance. This means we seek key features of biologic networks such as irregular firing patterns, robustness to noise, and locality. Additionally, we seek optimal performance when the network controls a given system.\\
If successful, we would obtain a general purpose controller that allows us to control any given linear system simply by plugging in the given system and the desired reference trajectory.\\

\section{Methodology}
To achieve our set goal, we first investigate what kind of Spiking network architecture to use. There are many different ways to design a \ac{SNN} each with its advantages and shortcomings. We aim to find an architecture that lies in between the most accurate biologic spiking model and yet allows some abstraction to apply it to our control problem.\\
Part of the goal is that the user does not have to interact with the neural network working underneath the control problem.
Firstly, we set out to achieve our goal by implementing a \ac{SNN} that allows us to simulate, not control, any given linear system with external inputs. With this network in place, another \ac{SNN} that acts as the controller will be built and combined with the first. The controller would generate a control signal that is used as external input to the first, returning the new system state to the controller in the process. Afterwards, we equip the network dedicated to simulation with the ability to learn the given system at hand.


\section{Outline}
In the next chapter, related work, as well as background information on autoencoders and different neural networks, is provided. This is combined with a summary of the different spiking network design choices. Next, the derivations of the spiking networks used for simulation and control are introduced in \cref{c:method}. Alongside, the learning rules are presented. In \cref{c:results} results on the simulating network, the control, and the learning are presented. For the simulation, a visual interpretation of the network dynamics is provided. In terms of control, important implementation details are highlighted, and necessary conditions to enable control are explained. Afterwards, results of the learning include a parameter study on both the un- and supervised learning rule used in this approach, as well as the study of limitations for the learning. These steps are then combined to accomplish our set-out goal of control. We explore two different implementations and highlight their limitations. Lastly, we conclude in \cref{c:conclusions} by summarizing our approach, its problems, and drawbacks. We furthermore express different points to improve the network's capabilities.
