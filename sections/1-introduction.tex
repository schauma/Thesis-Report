\chapter{Introduction}
\todi{
Provide a general introduction to the area for the degree project. Use references!\\
Link things together with references. This is a reference to a section: %\ref{sec:background}.
}


The human brain is a brilliant computing unit comprised of around 86 billion\cite{azevedo_equal_2009} neurons. Each of these neurons can have thousands of connections to other neurons. Between these connections, information travels trough the network as electrical impulses that interact with the neurons own electrical potential. With this network, the human brain is capable of performing vastly different and complex tasks. Machines and robots beat raw human computing power by several orders of magnitude, yet some tasks are next to impossible to solve by machines and classical algorithms alone. Moreover many machine implementations lack the speed, precision or flexibility of the human counterpart.\\
Researchers tried to combat this by mimicking the brain's internal network structure to solve problems deemed unsuitable for classic algorithms.\\
\acp{ANN} have shown a great success in previously hard to solve problems.\\
However the classical \acp{ANN} still struggle in context of control.
But where the highly abstract \acp{ANN} reach there limits a more biologically plausible network can overcome this obstacle.
Furthermore with newer more biologically inspired networks we are able to solve a broader range of problems. One prospect of these are \acp{SNN} which go so far as to simulate the discrete spiking behaviour of natural neural networks. So with this in mind we set out to design such a network in order to control a linear system.


\section{Background}
\label{sec:background}

The most common neural network architecture for \acp{ANN} are by far the feed-forward networks.
In these networks, information travels only in one direction and is not propagated by spikes but gradients of activation usually set in $[0,1]$ or $[-1,1]$.
These \acp{ANN} have made impressive progress in the fields of image recognition, autonomic driving, medical diagnosis\cite{patel_applications_2007} or  \ac{NLP} (using Transformers\cite{vaswani_attention_2017}).\\
This abstract representation bears advantages e.g in modelling and implementation but also gives away some key features of the human brain. Due to the information travelling only towards the output, feed-forward networks cannot build a memory or easily process temporal data. Recurrent models exist which allow for memory \cite{hutchison_biologically_2004} and sequential data input but loose some of the advantages compared to the Feed-Forward due to its increased complexity.\\
A third generation\cite{maass_networks_1997} of network architectures has risen, which aims to be even more biologically plausible. Inspired from nature, they implement spiking behaviour and recurrence found in the human brain.
This newer form of \ac{SNN} is as powerful as the classic feed-forward but suited for temporal data encountered in control.\\
While state of the art feed-forward networks are still outperforming \acp{SNN}\footnote{Most benchmarks are based on static information e.g. images which are adapted to \acp{SNN} and therefore do not allow a perfectly fair comparison.}, in some cases modern \acp{SNN} are on par or more performant with older feed-forward implementations. This comes with the added benefit of consuming much less power. Usually deep \acp{ANN} are run on \acp{GPU}, especially for training, in which the energy consumption can exceed 300W for modern chips\footnote{e.g. a NVidia RTX 3090}. The brain however is estimated to only consume about
20W \cite{clarke_circulation_1999} for immense computing capacity. Accompanying the \ac{SNN} with neuromorphic hardware can yield a similar boost in efficiency with processors energy consumption in the pJ per \ac{SOP}\cite{indiveri_importance_2019} offering a huge potential.


\todi{This is a separator}


Present the background for the area. Give the context by explaining the parts that are needed to understand the degree project and thesis. (Still, keep in mind that this is an introductory part, which does not require too detailed description).

Use references\footnote{You can also add footnotes if you want to clarify the content on the same page.}

Detailed description of the area should be moved to Chapter 2, where detailed information about background is given together with related work.



%\input{tables/sample-table}

\section{Problem}



\todi{Now list the goal: We want to do it for DS and check how good they are. Then method and then work. Take from below}


Conventional Feed-Forward neural networks do are not designed to work with temporal data. They are static input output machines. This makes sense in the context of many tasks but at the same time limits the power of these networks. There are workarounds to fit temporal data, for example by sampling the previous values back into the network used for example in time series forecasting \cite{tang_feedforward_1993}\cite{yang_cascade_2022}\cite{uncini_audio_2003} or to quantize the whole input if the complete time horizon is available. For example with recorded audio data.\\
Instead, recurrent neural networks are often proposed for these kinds of tasks. However recurrent neural networks experience problems when training with back-propagation\cite{bengio_learning_1994}. For \acp{RNN} and deep Feed-forward Neural Networks the gradients used in the back-propagation algorithm can explode or vanish. Different methods have been proposed to combat this problem, e.g. batch normalization\cite{ioffe_batch_2015}, using alternative activation functions(ReLU)\cite{nair_rectified_2010} or gradient clipping\cite{pascanu_difficulty_2013} to name a few. For recurrent models in particular different architectures have been suggested, most prominently among them the LSTM cell \cite{hochreiter_long_1997} with enormous success \cite{mayer_system_2006, sak_long_2014, li_constructing_2015}.\\
Yet, recurrent methods do not represent a very plausible formulation for biological networks. or biological movement\addref{true?}.
For the control of biological movements (often) \ac{LQR} is a proposed model for biological control \cite{li_iterative_2004}
Secondly when it comes to simulation of biologic dynamic systems usually \ac{LQG} control is used\addref{find refs}. LQG has been used widely for modelling biological movements and control.\rewrite{Add that LQR made many improvements but is also trash because of the matrix inversion, and nonlinear things in biology. Maybe also that it is an offline thing? Not sure whether thats true or if it is already online/can do noise but i believe yes.}
\todi{this is another smaller separator}
\acp{SNN} are inherently designed in time since neural impulses are integrated over time. This makes the use for temporal data natural.\\
The use of snn is online, can deal with much noise and offers an alternative way to reason for motor movement.

 \addref{backprop is not bio feasable bcs neurons are local and cannot traverse whole network}
 \addref{Feedforward have no memory. Makes it hard for many tasks to be useful. With recurrence you get memory.}
 \todi{add other snn models. e.g reach, sorn maybe or others,FORCE}
We hope that with SNN we have even better performance\\
From very biological to very abstract there have been many proposals\\
Cost performance trade off.\\
Spiking networks have gained similar or exceeding performance compared to the artificial one in some areas-> refs\\
Key advantage is in the temporal dimensional gain.\\
One field they are suited well is the control of dynamic systems\\
In this thesis we use a spiking neural network to control a linear dynamic system\\
The usual way to simulate biological dynamic systems is using LQG control -> ref\\
I believe because of the energy minimization\\
So we can compare them with usual NN and control in terms of performance... i guess\\
We start by giving an intro into spiking neural networks\\
Then spiking neural networks for dynamic systems\\
After control theory with SNN and maybe regular LQG control\\
Lately the learnign of SNNs for the control of dynamic system\\

Further work:\\
Maybe learning methods to control nonlinear dynamic systems\\
Maybe we can even do the adverserial attack to try to screw with the network.\\
Implement this on neuromorphic hardware\\

Problem:\\
Problem is that it is unnatural for classic NN to use temporal data.\\
They usually quantize it and make a big input layer -> ref\\
There are recurrent networks but ... they need to have smth bad as well\\
The LQG control is also not great for some reason I need to find\\
There are many spkiking network archetypes like poisson and GLm and balanced\\
Also problem is that for some spiking networks learning rules could be hard to come by.\\
There are many prospects though as for example ......->refs\\
Also usually learning rules smth of an inverse and that the brain does not have or do I believe arvind said\\



Method:\\
We use a SNN to to control any arbitrary DS\\
Balanced networks show a some key motives seen in the brain like poisson distribution and smth else ->ref\\
The SNN is to be trained with a STDP rule\\
Then compared to optimal weights\\
Then investigated about robustness and other things as many before\\
One part of robustness is trying to get the most essential nodes of the snn to function well.\\¸
Then we have the potential to find a classic nn and train it with that ???\\
With that out of the way we can compare the performance of all the methods.\\
Then we could study the usability for biological interpretation.\\
Maybe even train time over performance or smth whatever\\


Work:\\
Explain the controller method aka what the math of the controller\\
In method explain the balanced and the derivation\\
In work summarize the implementation\\
Same for the conventional NN\\
Summarize the training method\\
Explain and derive the training method in method\\


Results:\\
To everthign mentioned in method for performance and so on\\
Answer the questions of the problem!!!!\\


NN have excelled at many fields\\
Fields where they are not fit\\ aka temporal data\\
They have ways to compromise on that \\ -> reference\\
Spiking nn inherently temporal \\
more natural choice\\
However they also have problems\\
like the following:::: reference!!\\
\section{Purpose}
The purpose of the degree project/thesis is the purpose of the written material, i.e., the thesis. The thesis presents the work / discusses / illustrates and so on.

It is not “The project is about” even though this can be included in the purpose. If so, state the purpose of the project after purpose of the thesis).

Probably delete as a own paragraph but mention smth like that.



\section{Goal}
The goal means the goal of the degree project. Present following: the goal(s), deliverables and results of the project.\\

The goal of this project is to create a \ac{SNN} that can control any given linear \ac{DS}. Furthermore should the \ac{NN} be robust against failing neurons or connections. %With this we can investigate to find the smallest \ac{SNN} with acceptable performance.

We expect better results to conventional \acp{NN} because of the \ac{SNN}'s natural way to use temporal data. For the \ac{SNN} itself we desire to find the optimal balance between the biologic plausibility and performance. This means we seek key features of biologic networks such as irregular firing patterns, robustness to noise and locality. In addition to that we seek performance when we control the system.

To mimic the brain's learning, we want to use local training rules that are biologically plausible. The network should be converge to the optimal parameters.\\
Ideally, optimality should be reached, even though it is often not clear if this is possible. Already in highly researched \acp{ANN} this is usually a unattainably strong condition, as conventional \acp{NN} using \ac{GD} only guarantee a local optimum. \\
Furthermore in nature the brain does not offer separate between training and trial periods. The brain self-modulates its learning online without. This means that the network is expected to improve on itself as it working the task at hand.
Lastly, adjusting neural networks to a specific task is usually done by hand and requires time consuming hand tuning of parameters to achieve optimal results. Goal here is to automate as much of the process as possible i.e. the user does not need to adjust hyper-parameters himself. The network should be able to set itself up to find the best set of hyper-parameters given the task at hand, independent of the given control command or size of the system.
We do not seek a perfect spike similar representation of spiking dynamics found in nature but construct a more plausible attempt that could be used in neuromorphic hardware.
Lastly we are interested in the quality of the results if we restrict our methods to the natural limits of the brain.\\

If successful, we would obtain a general purpose controller that would allow us to control any given linear system just by plugging in the given system and the desired reference trajectory.\\
Furthermore we have a simple and robust controller that does not require expensive computation necessary for e.g. LQG controller.

\section{Methodology}
Introduce, theoretically, the methodologies and methods that can be used in a project and, then, select and introduce the methodologies and methods that are used in the degree project. Must be described on the level that is enough to understand the contents of the thesis.

Use references!

Preferably, the philosophical assumptions, research methods, and research approaches are presented here. Write quantitative / qualitative, deductive / inductive / abductive. Start with theory about methods, choose the methods that are used in the thesis and apply.


Detailed description of these methodologies and methods should be presented in Chapter 3. In chapter 3, the focus could be research strategies, data collection, data analysis, and quality assurance.

To achieve our set goal we first investigate what kind of Spiking network architecture to use. There are many different ways to design a \ac{SNN} each with its pros and cons.
We seek an architecture that lies in between the most accurate biologic spiking model and yet does not abstract to many features of nature.\\
After that we implemented a LQG controller a baseline reference.
Part of the goal is that the user does not have to touch the neural network working underneath the control problem.
Firstly, we set out to achieve this goal by implementing a \ac{SNN} that allows to simulate, not control, any given linear system with given external inputs. With this network in place it was set out to a second \ac{SNN} that acts as the controller and combining those two. The controller would generate a control signal that would be used as external input to return the system behaviour to the controller. In the end, this approach depended on hand-tuning hyperparameters to set the controller to give usable results which was in opposition to our goals.\\

To find these magic numbers we tried to implement a learning regime based on a similar approach. However this was unfruitful.
\todi{
Instead the original learning SNN approach is used to control the system directly.
}


\section{Outline}
In text, describe what is presented in Chapters 2 and forward. Exclude the first chapter and references as well as appendix.
\todi{make the outline in the end!}
First, we discuss why a biologic neural network is chosen compared to the more widely used \acp{ANN} in this task and what the goal is. In the