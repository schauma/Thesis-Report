\chapter{Introduction}

The human brain is a brilliant computing unit comprised of around 86 billion\cite{azevedo_equal_2009} neurons. Each of these neurons can have thousands of connections to other neurons. Between these connections, information travels trough the network as electrical impulses that interact with the neurons own electrical potential. With this network, the human brain is capable of performing vastly different and complex tasks. Machines and robots beat humans in raw computing power by several orders of magnitude, yet many tasks are next to impossible to solve by machines and classical algorithms alone. Moreover, many machine implementations lack the speed, precision or flexibility of the human counterpart.\\
Researchers tried to combat this by mimicking the brain's internal network structure to solve problems deemed unsuitable for classic algorithms.\\
\acp{ANN} have shown a great success in previously hard to solve problems.\\
However the classical \acp{ANN} still struggle in context of control.
But where the highly abstract \acp{ANN} reach there limits a more biologically plausible network can overcome this obstacle.
\acp{SNN} compute and simulate spiking rates or even extend to calculating individual spikes to mimic natural neural networks. With this leap in complexity also comes the advantage of enhanced computing power. Furthermore, with newer more biologically inspired networks we are able to solve a broader range of problems. Using \acp{SNN}, we set out to design such a network in order to control a linear system.  \\

\section{Background}\label{sec:background}

The most common neural network architecture for \acp{ANN} are the feed-forward networks.
In these networks, information travels only in one direction and is not propagated by spikes but gradients of activation usually set in $[0,1]$ or $[-1,1]$.
These \acp{ANN} have made impressive progress in the fields of image recognition, autonomic driving, medical diagnosis\cite{patel_applications_2007} or  \ac{NLP} (using Transformers\cite{vaswani_attention_2017}).\\
This abstract representation brings advantages e.g in modelling and implementation but also gives away some key features of the human brain. Due to the information travelling only towards the output, feed-forward networks cannot build a memory or easily process temporal data. Recurrent models exist which allow for memory \cite{hutchison_biologically_2004} and sequential data input but loose some of the advantages compared to the Feed-Forward due to its increased complexity.\\
A third generation\cite{maass_networks_1997} of network architectures has risen, which aims to be even more biologically plausible. Inspired from nature, they implement spiking behaviour and recurrence found in the human brain.
This newer form of \ac{SNN} is as powerful as the classic feed-forward but suited for temporal data encountered in control.\\
While state of the art feed-forward networks are still outperforming \acp{SNN}\footnote{Most benchmarks are based on static information e.g. images which are adapted to \acp{SNN} and therefore do not allow a perfectly fair comparison.}, in some cases modern \acp{SNN} are on par\cite{lee_training_2016} or more performant with previous feed-forward implementations consuming less energy.

%\input{tables/sample-table}

\section{Problem}
Conventional Feed-Forward neural networks do are not designed to work with temporal data. They are static input output machines. This makes sense in the context of many tasks but at the same time limits the power of these networks. There are workarounds to fit temporal data, for example by sampling the previous values back into the network used for example in time series forecasting \cite{tang_feedforward_1993}\cite{yang_cascade_2022}\cite{uncini_audio_2003} or by quantizing the whole input if the complete time horizon is available i.e. with recorded audio data.\\
Instead of these workarounds, recurrent neural networks are often proposed for these kinds of tasks. However recurrent neural networks experience problems when training with back-propagation\cite{bengio_learning_1994}. For \acp{RNN} and deep Feed-forward Neural Networks the gradients used in the back-propagation algorithm can explode or vanish. Different methods have been proposed to combat this problem, e.g. batch normalization\cite{ioffe_batch_2015}, using alternative activation functions(ReLU)\cite{nair_rectified_2010} or gradient clipping\cite{pascanu_difficulty_2013} to name a few. For recurrent models in particular different architectures have been suggested, most prominently among them the LSTM cell \cite{hochreiter_long_1997} with proven success \cite{mayer_system_2006, sak_long_2014, li_constructing_2015}.\\
Yet, these recurrent designs are not a plausible representation of biological networks.
\acp{RNN} still operate on a continuous range of values instead of discrete spikes. Utilizing the continuity, they are trained with the biologically implausible global learning rules such as the Back-Propagation algorithm.\\
Furthermore, \acp{SNN} come with the added benefit of consuming less power. Usually deep \acp{ANN} are run on \acp{GPU}, especially for training, in which the energy consumption can exceed 400W for modern chips\footnote{e.g. a NVidia RTX 4090}. The brain however is estimated to only consume about
20W \cite{clarke_circulation_1999} for its immense computing capacity. Accompanying the \ac{SNN} with neuromorphic hardware can yield another boost in efficiency with processors energy consumption in the pJ per \ac{SOP}\cite{indiveri_importance_2019} offering huge potential power savings.


\section{Goal}\label{sec:goal}
The goal of this project is to create a \ac{SNN} that can control any given \ac{LTI} system. Furthermore should the \ac{NN} be robust against failing neurons or connections.\\
As an additional constraint, the goal should be reached by using biologically tractable methods as much as possible.\\
To mimic the brain's learning, we want to use local training rules that are biologically plausible.\\
Ideally, optimality should be reached, even though it is often not clear if this is possible. Already in highly researched \acp{ANN} this is usually a unattainably strong condition, as conventional \acp{NN} using \ac{GD} only guarantee a local minima.\\
Furthermore in nature the brain does not offer separate between training and trial periods. The brain self-modulates its learning online without. This means that the network is expected to improve on itself as it working the task at hand.\\
Lastly, adjusting neural networks to a specific task requires time to tune hyper-parameters by hand to achieve optimal results. Goal here is to automate as much of the process as possible such that the network does not need to get adjusted manually. The network should find acceptable solutions given the task at hand, independent of the given control command or size of the system without problem specific adjustments of hyper-parameters.\\
For the \ac{SNN} itself we desire to find a balance between the biologic plausibility and performance. This means we seek key features of biologic networks such as irregular firing patterns, robustness to noise and locality. Additionally, we seek performance when the network controls a given system.\\
If successful, we would obtain a general purpose controller that would allow us to control any given linear system just by plugging in the given system and the desired reference trajectory.\\
Furthermore we have a simple and robust controller that would not require expensive computation necessary for e.g. LQG control.

\section{Methodology}
To achieve our set goal we first investigate what kind of Spiking network architecture to use. There are many different ways to design a \ac{SNN} each with its advantages and shortcomings.
We seek an architecture that lies in between the most accurate biologic spiking model and yet does allow some abstraction to apply it to our control problem.\\
Part of the goal is that the user does not have to touch the neural network working underneath the control problem.
Firstly, we set out to achieve our goal by implementing a \ac{SNN} that allows to simulate, not control, any given linear system with  external inputs. With this network in place another \ac{SNN} that acts as the controller will be build and combined with the first. The controller would generate a control signal that would be used as external input to the first returning the new system state to the controller in the process.\\
Afterwards, we equip the network dedicated to simulation with the ability to learn the given system at hand.\\
Lastly, we combine the two networks into one in order to enable a spiking learning rule at the cost of having to disregard the input matrix.\\\todo[inline]{Is the last paragraph in the right place here?}

\section{Outline}
\todi{make the outline in the end!}

First, we discuss why a biologic neural network is chosen compared to the more widely used \acp{ANN} in this task and what the goal is. In