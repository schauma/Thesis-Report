\chapter{<Engineering-related content, Methodologies and Methods>}
% \thispagestyle{fancy}

\todo{Research question: Develop a biologically sensible SNN to control any linear dynamical system.}
\todi{Research question: Develop a biologically sensible SNN to control any linear dynamical system.}


\section{Choice of Network architecture}

The field of \acp{SNN} is under ongoing research. Therefore many different network models and learning approaches have been proposed e.g. \acp{LSM}\cite{dewolf_spiking_2016}. In order to stay biologically more realistic we ignore purely rate based spiking networks as there is evidence that the precise spike timing is relevant in nature\cite{brette_philosophy_2015}\cite{putney_precise_2019}.
On the other side of the specturm it makes little sense to use \ac{HH}'s model. Even though it is very biologically plausible its increased complexity and little abstraction makes it more suited for solely accurate biological neural simulation and less for the engineering task at hand. Additionally there are no training/learning rules available to solve such a high level problem.\\


Explain choice of SNN architecture\\
HH doesnt make sense because to complex.\\
Recurrent models are possible but also not biologic enough because we want to use the spiking property\\
LSM was considered but in a LSM you only learn the decoder. For the problem at hand is is more natural to have the dynamics in a neural network. Plus with this approach we learn the decoder as well so there it makes it for a more independent approach.\\



Design a LQG controller to start with as reference
First found how to simulate a dynamical system with given input c from Boerlin\\
Then finding the controller structure to find exteral input c to control the system in a desired way\\
Then notice you need to have magic numbers to get it to work properly.\\
Then trying to bring the learning mechanics to that approach.\\
Deemed difficult\\
finding way to control a dynamical system with the learning SNN framework\\
Also not so far to do nonlinear systems\\


Describe the engineering-related contents (preferably with models) and the research methodology and methods that are used in the degree project.

Most likely it generally describes the method used in each step to make sure that you can answer the research question.


\section{Simulation of Dynamic systems using \acp{SNN}}\label{sec:simulation}
In the following sections the simulation of dynamic systems using \acp{SNN} is derived and explained. This serves as the a basic building block for the attempted method on how to solve our target set out in section\todi{add reference to the goal section}. We begin with the formal derivation of the network dynamics.
\subsection{Balanced network simulation}\label{ssec:balanced_network_sim}

This section follows the derivation found in \cite{boerlin_predictive_2013} and \cite{huang_dynamics_2019}.
The goal is to describe a dynamical system of the form
\begin{equation}\label{eq:x}
\bmu{\dot{x}} = \bmu{Ax} + \bmu{c}(t)
\end{equation}
with $J$ state variables.
The estimation is done by leaky integration of spike trains $\symbfup{o}(t)$ in
\begin{equation}\label{eq:x_hat}
\bmu{\dot{\hat{x}}} = -\lambda_d \bmu{\hat{x}} + \symbfup{\Gamma} \bmu{o}(t).
\end{equation}
$\bmu{\Gamma}$ is a given Matrix of size $\mathbb{R}^{J\times N}$, $N$ being the number of neurons. This matrix is given as initial and can be optimized by training later on\cite{brendel_learning_2020}.\\
In addition to the estimate $\bmu{\hat{x}}$ we define a spiking rate variable $\bmu{r}$ following the dynamics of
\begin{equation}\label{eq:rate}
\bmu{\dot{r}} = -\lambda_d\bmu{r} + \bmu{o}(t).
\end{equation}
The rate variable is connected to the state vector in the decoding with
\begin{equation}\label{eq:decoding}
	\bmu{\hat{x}} = \bmu{\Gamma r}.
\end{equation}

\todi{explain how this is better than just rate encoding}
The spiking dynamics arise from the minimization of a cost function. A spike is fired if it minimizes the cost function that tracks the error between the true and estimated value over time
\begin{equation}\label{eq:cost_func_basic}
E(t)=\int_0^t \|\symbfup{x}(u)-\hat{\symbfup{x}}(u)\|_2^2 \ du.
\end{equation}


\subsection{Greedy optimization of the cost}
The cost function \cref{eq:cost_func_basic} is minimized using a greedy optimization i.e. a spike is fired if it reduces the cost. For the derivation we use the cost function \cref{eq:cost_func} which is identical to setting $\mu = 0,\nu= 0$.\\
We express this as
\begin{equation}\label{eq:spike_condition}
	E(t|i \text{ spike}) < E(t,i \text{ }\overline{\text{spike}})
\end{equation}

If there is no spike fired, the rate and estimated state variable in \cref{eq:x_hat} and \cref{eq:rate} respectively behave as
\begin{equation}\label{eq:no_spike_decay}
\begin{aligned}
\bmu{\dot{\hat{x}}} &= -\lambda_d \bmu{\hat{x}}\\
\bmu{\dot{r}} &= -\lambda_d\bmu{r}
\end{aligned}
\end{equation}
and therefore decay exponentially with $e^{-\lambda_d t}$.\\
If a spike is fired at time $t^k$, the inhomogeneous solution is found by variation of constants in \cref{eq:rate} to
\begin{equation}\label{eq:rate_inhomo}
\begin{aligned}
r_i^h &= c_i(t)e^{-\lambda_d t}\\
c_i'(t) e^{-\lambda_d t} - c_i(t)\lambda_d e^{-\lambda_d t}&= -\lambda_d c_i(t)e^{-\lambda_d t} + \delta(t- t^k)\\
c_i'(t) &= \delta(t- t^k) e^{\lambda_d t}\\
c_i(t) &=  e^{\lambda_d t^k} \bm{H}(t-t^k)\\
r_i &=e^{-\lambda_d t} + e^{-\lambda_d (t-t^k)} \bm{H}(t-t^k).
\end{aligned}
\end{equation}
The last equation is the identical the solution of \cref{eq:no_spike_decay} with the addition of a decaying exponential added at time $t_i^k$. $\bm{H}(t)$ denotes the Heaviside step function . Analogously the estimate is updated at time $t^k$ to
\begin{equation}\label{eq:update_x_spike}
	\bmu{x} =  \bmu{x} + \bmu{\Gamma}_ie^{-\lambda_d (t-t^k)} \bm{H}(t-t^k).
\end{equation}
We look at the error a $\epsilon$ time in the future of $t^k$ and check \cref{eq:spike_condition}
\begin{equation}
\begin{aligned}
& \int_0^{t^k+\epsilon} \left(\underbrace{\left\|\bmu{x}(u)-\hat{\bmu{x}}(u)-\bmu{\Gamma}_i h(u-t^k)\right\|_2^2}_{\text{I}}+
\underbrace{\nu\left\|\bmu{r}(u)+\lambda_d \bmu{e}_i h(u-t^k)\right\|_1}_{\text{II}}\right.\\
& \left.+\underbrace{\mu\left\|\bmu{r}(u)+\lambda_d \bmu{e}_i h_d(u-t)\right\|_2^2}_{\text{III}}\right) d u\\
& <\int_0^{t^k+\epsilon} \left(\|\bmu{x}(u)-\hat{\bmu{x}}(u)\|_2^2+\nu\|\bmu{r}(u)\|_1+\mu\|\bmu{r}(u)\|_2^2\right)d u
\end{aligned}
\end{equation}
where we abbreviated $h(u) = e^{-\lambda_d (u)} \bm{H}(u)$.
To treat each term individually we start with I. Simplifying the norm we obtain
\begin{equation}
	\text{I} = \left\|\bmu{x}(u)-\hat{\bmu{x}}(u)\right\|_2^2 -2h(u-t^k)\bmu{\Gamma}_i^T\left(\bmu{x}(u)-\hat{\bmu{x}}(u)\right) + h^2(u-t^k)\bmu{\Gamma}_i^T\bmu{\Gamma}_i.
\end{equation}
For II the 1-norm and the rate holds that the $r_i(u)>0 \quad
\forall i$. Thus we can simplify $\|r\|_1 = \sum_k r_k$ resulting in
\begin{equation}
	\text{II} = \nu\left(\|r\|_1 + h(u-t^k)\right).
\end{equation}
Similarly to I, III can be simplified by $\|\bmu{r}\|^2_2 = \bmu{r}^T\bmu{r}$, giving
\begin{equation}
	\text{III} = \mu\|\bmu{r}\|^2_2 + \mu h^2(u-t^k) + 2\bmu{r}\cdot\bmu{e}_ih(u-t^k).
\end{equation}
After cancellation the remaining terms are grouped grouped by time dependency to yield
\begin{equation}
\begin{aligned}
	&\int_0^{t^k+\epsilon}h(u-t^k)\bmu{\Gamma}_i^T\left(\bmu{x}(u)-\hat{\bmu{x}}(u)\right) - \mu r_i(u) d u \\
	&> \frac{1}{2} \int_0^{t^k+\epsilon} 	h^2(u-t^k)\bmu{\Gamma}_i^T\bmu{\Gamma}_i + 	\nu h(u-t^k) + \mu h^2(u-t^k) d u
\end{aligned}
\end{equation}
Using the fact that the Heaviside function in \cref{eq:rate_inhomo} and subsequently in $h(u)$ allow us to change the borders of integration to $\int_{t^k}^{t^k+\epsilon}$. Lastly we simplify $h(t) = 1$ if $t\approx \epsilon$ and have
\begin{equation}
	\bmu{\Gamma}_i^T\left(\bmu{x}-\hat{\bmu{x}}\right) - \mu r_i>\frac{\|\bmu{\Gamma}\|^2 + \nu + \mu}{2}
\end{equation}
We notate the \ac{LHS} as the voltage and the constant \ac{RHS} as the voltage threshold $T_i$


\begin{equation}\label{eq:condition}
V_i>T_i=\frac{\left\|\boldsymbol{\bmu{\Gamma}}_i\right\|^2 + \nu+\mu}{2}.
\end{equation}
\rewrite{Remember that i read somewhere that the noise is necessary. Maybe mention that here too. And find the reference}



\subsection{Neuron Voltage}
As mentioned above, a neuron spikes if it meets the condition \cref{eq:condition}. But so far it is unclear how neuron voltage evolves over time.
Denote $\bmu{L}$ the the left pseudo-inverse of $\bmu{\Gamma}$ \begin{equation}
\bmu{L} = \left(\bmu{\Gamma}\bmu{\Gamma}^T\right)^{-1}\bmu{\Gamma}
\end{equation}
such that $\bmu{L}\bmu{\Gamma}^T = \bmu{I}$.\\
Next, taking the derivative of \cref{eq:voltage} yielding
\begin{equation}\label{eq:voltage_dt}
\bmu{\dot{V}}(t)=\bmu{\Gamma}^T\left(\bmu{\dot{x}}(t)-\dot{\hat{\bmu{x}}}(t)\right)-\mu \bmu{\dot{r}}(t).
\end{equation}
Now using the pseudo-inverse to rewrite the voltage equation \cref{eq:voltage} as
\begin{equation}\label{eq:voltage_2}
\begin{aligned}
\bmu{V}(t)&=\bmu{\Gamma}^T(\bmu{x}(t)-\hat{\bmu{x}}(t))-\mu \bmu{r}(t)\\
\bmu{L}\bmu{V}(t)&=(\bmu{x}(t)-\hat{\bmu{x}}(t))-\mu \bmu{L}\bmu{r}(t)\\
\bmu{x}(t)&=\bmu{L}\bmu{V}(t)  + \hat{\bmu{x}}(t) + \mu \bmu{L}\bmu{r}(t)\\
\end{aligned}
\end{equation}
Now the derivative terms in \cref{eq:voltage_dt} are replaced with  with their respective equations \cref{eq:x}, \cref{eq:x_hat} and \cref{eq:rate}. Lastly we substitute \cref{eq:voltage_2} in \cref{eq:voltage_dt} and obtain
\begin{equation}\label{eq:voltage_limit}
\begin{aligned}
	\bmu{\dot{V}} &= \bmu{\Gamma}^T\bmu{ALV}\\
	 &+ \left(\bmu{\Gamma}^T\bmu{A\Gamma} + \mu\bmu{\Gamma}^T \bmu{AL}+\lambda_d\bmu{\Gamma}^T\bmu{\Gamma + \mu\lambda_d}\right)\bmu{r}\\
	 &+\left(\bmu{\Gamma}^T\bmu{\Gamma} + \mu\right)\bmu{o} + \bmu{\Gamma}^T\bmu{c}.
\end{aligned}
\end{equation}
The last argument is to consider the network behaviour for larger networks. We increase the number of neurons $N\longrightarrow\infty$ and require that the network output as well as the firing rates remains constant.\\
When looking at the decoding at \cref{eq:decoding} we therefore need to scale $\bmu{\Gamma}$ by $\frac{1}{N}$. To make sure that the threshold in \cref{eq:condition} will not get dominated by cost terms $\mu$ \& $\nu$, they should also scale with $\frac{1}{N^2}$. As the threshold decreases with $\frac{1}{N^2}$ so does the Voltage itself.\\
With this in mind, all terms that scale with $\frac{1}{N^2}$ are neglected. As a substitute for the neglected voltage term, a generic leak term is added making these \acp{LIF} neurons. The dynamics are therefore
\begin{equation}
\begin{aligned}
	\bmu{\dot{V}} &= -\lambda_V \bmu{V} + \bmu{W^sr} + \bmu{W^fo} + \bmu{\Gamma}^T \bmu{c}\\
	\bmu{W^s} &= \bmu{\Gamma}^T\bmu{(A+\lambda}_d\bmu{I)\Gamma}\\
	\bmu{W^f} & = -\left(\bmu{\Gamma}^T\bmu{\Gamma} + \mu\bmu{I}\right)
\end{aligned}
\end{equation}






\todi{find a coherent name for the matrix}



\subsection{Regularization}\label{sssection:regularization}

Two regularization terms are added to influence spiking behaviour.\\
\begin{equation}\label{eq:cost_func}
E(t)=\int_0^t \left(\|\symbfup{x}(u)-\hat{\symbfup{x}}(u)\|_2^2+\nu\|\symbfup{r}(u)\|_1+\mu\|\symbfup{r}(u)\|_2^2\right)d u
\end{equation}

The parameter $\nu$ controls the amount of spiking by penalizing the total number of spikes as
\begin{equation}
||r(t)||_1 = \sum_i|r_i(t)| = \sum_i r_i(t).
\end{equation}
The firing rate is directly related to the number of spiking and therefore the cost is reduced by fewer spikes.\\
The second term solves different issues at the same time. One problem concerns networks that have decoding kernels with the same direction but opposite sign. To show this we imagine a network of only two neurons. A network of two neurons is sufficient to simulate a scalar \ac{ODE} i.e $\bmu{A}\in \mathbb{R}$. We further assume that the kernel has the form
\begin{equation}
\Gamma = \begin{bmatrix}
-1\\1
\end{bmatrix}
\end{equation}
Ignoring the cost terms in \cref{eq:condition} the threshold is set at
\begin{equation}
V_i > \frac{\|\bmu{\Gamma}_i\|^2}{2}
\end{equation}
after which that a spike is fired and the voltage of neuron $i$  resets to
\begin{equation}
V_i = V_i + \bmu{W^s}_{ii} = V_i + \|\bmu{\Gamma}_i\|^2_2 \quad \text{ with } \bmu{W^f} = \begin{bmatrix}
-1& 1\\
1& -1
\end{bmatrix}
\end{equation}
ideally setting the Voltage to $-T_i$. This can be seen when looking at the threshold as
\begin{equation}
T_i =\frac{ \bmu{\|\Gamma}_i\|^2}{2}= \frac{-\text{diag}(\bmu{W^f})}{2}.
\end{equation}
The repolarization of the spiking neuron acts as a depolarization or pushing the voltage towards its threshold for neurons with opposing sign. The problem now is that for neurons with the same kernel magnitude the depolarization is larger enough to push this neuron over the threshold. The subsequent spike re-polarizes the neuron but in turn excites the first neuron over its threshold. This pattern repeats and destroys network performance.\\\addref{maybe a picture}
For the given example above, the threshold is given by 0.5 for both. The neurons' voltages of are identical up to the sign, since they are tracking the error for the same variable. At the time one neurons reaches the threshold of 0.5 the second neuron's voltage is close to -0.5 considering noise (in a perfect system minus the value of the spiking neuron). After the spike is fired, the first neuron is reset to -0.5 stemming from
\begin{equation}\label{eq:reset}
\begin{aligned}
\bmu{V} &= \bmu{V} + \bmu{W^fo} = \bmu{V} + \bmu{W^f}\begin{bmatrix}
1\\
0
\end{bmatrix} = \bmu{V} + \bmu{W^f}_{:0}\\
\bmu{V} &= \begin{bmatrix}
0.5\\
-0.5\\
\end{bmatrix} +
\begin{bmatrix}
-1\\
1\\
\end{bmatrix} =
\begin{bmatrix}
-0.5\\
0.5
\end{bmatrix}
\end{aligned}
\end{equation}
$\bmu{W^f}_{00}$ whereas the second neuron gets pushed up to 0.5 , causing a spike. This in turn reverts the changes of \cref{eq:reset} resulting in a loop. This problem is caused by the greedy optimization, looking only at the immediate future to decrease the cost.\\
To fix this we set the threshold slightly higher. As seen above in \cref{eq:condition}, this can be done by either raising the linear or quadratic cost.\\
The second issue fixed by adding quadratic cost is when there are
neurons with similar kernel direction but non normalized. In a perfect noise free scenario the neuron with the smaller threshold will always fire first. The neurons reset after the spike will reset the neurons with similar direction, inhibiting the second neuron from ever firing. The linear cost do not make a difference since it is penalizing the global number of spikes but does not discern where the spikes are fired. With the quadratic cost the norm of spike rates distributed among many neurons is reduced compared to few.

\vspace{2cm}
\hrule
The first was termed "ping-pong" effect and is described in the supplementary material of \cite{boerlin_predictive_2013}. To understand the issue, we imagine a minimal network consisting of 2 neurons with equal kernel but opposite sign. \rewrite{Write better the ping pong effect! Maybe later}\\


The second regularization comes into play when there are kernels with different magnitude. Kernels with small kernel magnitude reach their threshold sooner and therefore fire more frequently. In the extreme case, only small number of neurons fire rapidly while the majority remains idle. By penalizing the rate in the 2-norm it forces the network to spread the firing among the whole network.\\\rewrite{find the right place to explain that!}


The dynamic variable $\bmu{x}$ is tracked by firing spikes in when the defined "pseudo voltage" of a neuron surpasses its threshold. The voltage for each neuron is defined by
\begin{equation}\label{eq:voltage}
V_i(t)=\bmu{\Gamma}^T(\bmu{x}(t)-\hat{\bmu{x}}(t))-\mu \lambda_d r_i(t)
\quad i  = 1\dots N.
\end{equation}
For negligible quadratic cost $\mu$ the voltage can be understood as measure of the error projected on $\bmu{\Gamma}_i$. The explicit derivation of the above equation is found in \cite{boerlin_predictive_2013} and will be adapted \rewrite{Where? Here, in the appendix of at all?}.
\section{Control of Dynamic systems using \acp{SNN}}
\subsection{Balanced networks as a controller}
We now make the step to use the balanced network approach from above as a controller mechanism.\\
The idea was taken from \cite{huang_optimizing_2017} and is illustrated in \cref{fig:schematic}. With the given reference signal, the network receives the feedback error of the system. The networks spikes are decoded into a control signal which is further fed into the dynamical system.\\
The system itself is simulated using a common numerical method i.e. explicit Euler. Yet the goal is to capture the entire problem using \acp{SNN}. The control signal $\bmu{u}$ is generated using the an independent \ac{SNN} which is in turn the command $c$ for a separate \ac{SNN} simulating the states with feedback to the controlling \ac{SNN}.
\begin{figure}
	\centering
	\todi{Add figure}
	\caption{Schematic to illustrate the use of balanced networks as controllers.}
	\label{fig:schematic}
\end{figure}
\subsection{Dynamics}
The derivation of this method is similar to the one in \cref{sec:simulation}. Names and variables are reused if not stated here.\\
The system in question has the form
\begin{equation}\label{eq:contsys}
	\bmu{\dot{x}} = \bmu{Ax} + \bmu{Bu}.
\end{equation}
The basic definitions of the \ac{SNN} remain the same with rate $\bmu{r}$ as well as decoding weights $\bmu{\Gamma}$. Additionally, \cite{huang_optimizing_2017} defines instantaneous decoding weights $\bmu{\Omega}$ with the same shape as $\bmu{\Gamma}\in \mathbb{R}^{J\times N}$. It is important to note that $J$ does not represent the number of state variables but the number of inputs. The decoding is the same as in \cref{eq:decoding} with the added $\bmu{\Omega}$ giving.
\begin{equation}
	\bmu{u}(t) = \bmu{\Gamma r} + \bmu{\Omega o}.
\end{equation}
The derivation of the network dynamics in \cite{huang_dynamics_2019} is similar to \cite{boerlin_predictive_2013} and the derivation presented above. Differences arise in the computation of the cost function as the spike changes the system to
\begin{equation}\label{eq:control_spike_change}
	\begin{aligned}
	\bmu{u} &= \bmu{u} + h(t-t^k)\bmu{\Gamma}_k + \bmu{\Omega}_k\\
	\bmu{r} &= \bmu{r} + h(t-t^k)\bmu{e}_k\\
	\bmu{\hat{x}} &= \bmu{\hat{x}} + h(t-t^k)\int_{0}^{t-t^k}e^{(\bmu{A}+\lambda_d\bmu{I})\zeta}d\zeta \bmu{B\Gamma}_k + e^{A(t-t^k)}\bmu{B\Omega}_k
	\end{aligned}
\end{equation}
where $\bmu{\Gamma}_k$ and $\bmu{\Omega}_k$ correspond to the $k$-th column of $\bmu{\Gamma}$, $\bmu{\Omega}$ and $h$ the same as defined above. Results are similar for the rate and control signal whereas the state update is obtained by formally integrating the system. The rest of the derivations are analogous and completely derived in \cite{huang_optimizing_2017}. The results summarize to \crefrange{eq:control_dyn_begin}{eq:control_dyn_end}.
\begin{align}
	\bmu{V} &= \bmu{\Omega}^T\bmu{B}^T\left(\bmu{x} -\bmu{\hat{x}}\right) - \mu \bmu{r}\label{eq:control_dyn_begin}\\
	\bmu{\dot{V}} &= -\lambda_V\bmu{V} + \bmu{\Omega}^T \bmu{B}^T \bmu{c}(t) + \bmu{W^fo} + \bmu{W^sr}\label{eq:control_dyn_2}\\
	\bmu{c} &= \bmu{\dot{x}} - \bmu{Ax}\\
	\bmu{W^f} &= - \left(\bmu{\Omega}^T\bmu{B}^T\bmu{B\Omega} + \mu\bmu{I}\right)\\
	\bmu{W^s} &= -\bmu{\Omega}^T\bmu{B}^T\bmu{B\Gamma}\\
	T_i &= \frac{\bmu{\Omega}_i^T\bmu{B}^T\bmu{B\Omega}_i + \nu  + \mu}{2}
	\label{eq:control_dyn_end}
\end{align}
Note that the notation differs in the original paper and the reference signal is denoted by $\bmu{\hat{x}}$ instead of $\bmu{x}$ here and $\bmu{\Omega}_i$ again refers to the $i$-th column of $\bmu{\Omega}$.
\subsection{The instantaneous decoding weights}
The necessity of instantaneous decoding is necessary otherwise no spiking can occur. In \cref{eq:control_spike_change} the control signal is integrated with the matrix exponential. The problem is that the integral
\begin{equation}
	\lim_{t\longrightarrow 0 } \int_0^t e^{(\bmu{A}+\lambda_d\bmu{I})\zeta}d\zeta = 0
\end{equation}
for our small $\epsilon$ time horizon.\\
This is true for any matrix exponential $e^{\bmu{\Lambda}\zeta}$ seen by Taylor expansion
\begin{equation}
	\begin{aligned}
	\lim_{t\longrightarrow 0 }\int_0^t e^{\bmu{\Lambda}\zeta}d\zeta &= \lim_{t\longrightarrow 0 } \int_0^t \sum_{k=0}^\infty \frac{\left(\bmu{\Lambda}\zeta\right)^k}{k!} d\zeta\\
	&=\lim_{t\longrightarrow 0 }\sum_{k=1}^\infty t\frac{\left(\bmu{\Lambda}t\right)^{k-1}}{k!} = 0.
	\end{aligned}
\end{equation}
This means that the rate decoding vanishes in the derivation of \crefrange{eq:control_dyn_begin}{eq:control_dyn_end}. Therefore the firing threshold condition becomes
\begin{equation}
	-\mu \bmu{r}_i > \frac{\nu  + \mu}{2}
\end{equation}
if $\bmu{\Omega}$ is ignored which is an insatiable condition since $\bmu{r}$ is always non-negative.
\subsection{Extension with direct Error feedback}
The same group of \cite{huang_optimizing_2017} later published a new but very similar approach in \cite{huang_spiking_2019} which is based on the same idea, however the approach in \cite{huang_spiking_2019} makes the error a direct part of the voltage dynamics. The difference arises from the an new derivation avoiding the pseudo-inverse $\bmu{L}$.\\
Instead, during the analogous step of \cref{eq:voltage_dt} they set $\bmu{\hat{x}}$
and $\bmu{x}$ to follow the same dynamics, namely
\begin{equation}
	\bmu{\dot{x}} = \bmu{Ax} + \bmu{c}(t)
\end{equation}
for the reference signal and
\begin{equation}
	\bmu{\dot{\hat{x}}} = \bmu{A\hat{x}} + \bmu{Bu}
\end{equation}
for the system.\\
In total this adjustment changes the dynamics of \cref{eq:control_dyn_2} to
\begin{equation}
	\bmu{\dot{V}} = -\lambda_V\bmu{V} + \bmu{\Omega}^T \bmu{B}^T\bmu{Ae}(t) + \bmu{\Omega}^T \bmu{B}^T \bmu{c}(t) + \bmu{W^fo} + \bmu{W^sr}.
\end{equation}
Important to note is that due to the investigation of the network's limit behaviour in \cite{huang_optimizing_2017}, similarly done in \cref{eq:voltage_limit} and the subsequent neglect of certain terms, changes the definition of $\bmu{W^s}$. In the derivation in \cite{huang_spiking_2019} this is not done and therefore terms remain changing $\bmu{W^s}$'s definition to
\begin{equation}
	\bmu{W^s} = -\bmu{\Omega}^T\bmu{B}^T\bmu{B\Gamma} + \mu\bmu{I}.
\end{equation}
\todi{add that there is always noise somewhere}

\subsection{Direct feedback}

\todi{Write here that approach that I didnt do yet.}

\section{Engineering-related and scientific content:}
Applying engineering related and scientific skills; modelling, analysing, developing, and evaluating engineering-related and scientific content; correct choice of methods based on problem formulation; consciousness of aspects relating to society and ethics (if applicable).

As mentioned earlier, give a theoretical description of methodologies and methods and how these are applied in the degree project.


was ist meine research question?

zusammensetzung von den beiden systeme: dynamisches system und neuronales netz. mehr oder weniger die herleitung kopieren aus dem paper. Dann mit learning von den gewichten.





Here I describe what how it needs to be done.
So this is the place for the derivation
The concept and the process whatever that means
Later there comes the how I implemented it.
Here is what we needs to be implemented.



Here very detailed explanation of the Balanced network for this problem\\
Very detailed way for the regular NN for this problem
Basics of the controller design used in this comparison aka LQG controller\\
Method of learning the weights for the SNN
Method of comparison\\