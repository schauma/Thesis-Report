\chapter{Conclusions}\label{c:conclusions}

The development of the spiking neural network controller for controlling a linear system involved three distinct stages. The controller utilized the Efficient balanced coding scheme, incorporating biologically plausible principles. In the initial stage, simulation, the \ac{SNN} was capable of simulating any given dynamical system using analytically calculated values.\\

As a second step, a dedicated controller was designed to generate the control signal $\bmu{u}$. This controller, built on the same \ac{SNN} architecture, was added in front of the previous stage to generate the necessary control signals. The controller, when combined with the previous stage demonstrated effective control over the system dynamics. However, it's worth noting that the effectiveness of the control stage was contingent on specific conditions related to the control problem, limiting its general applicability.\\
Moreover, the dynamics of the control stage were predominantly stemming from the definition of the external inputs $\bmu{c}$ rather than the entire network. For control, $\bmu{c}$ served as a forcing term to the network, bridging the necessary input to push the network into following the desired trajectory. The main objective of the control network was the generation of spikes and subsequent output of the control signal $\bmu{u}$.\\
The purely open loop design of the control encountered the typical design challenges e.g. in aspects of noise or system error. In a separate similar derivation the emerging explicit error term was insignificant in combatting these issues.\\

Thirdly, the analytically derived network dynamics of the first stage were learned using local learning rules. The fast recurrent dynamics were learned by an unsupervised learning rule while the slow dynamics were trained through a supervised student-teacher approach. The learning performance was examined, with parameters fine-tuned to yield a significant improvement in network accuracy for our model problem. Challenges in the learning process were primarily assiciated with the random initialization of the matrices intended for training, scaling of the learning rate, form of the training input sequences and the initialization of $\bmu{\Gamma}$. Higher-dimensional problems, in general, were only applicable in specific cases with manual parameter tuning, yielding mixed results overall.\\

In the final step, when applying the previously learned matrices with the control scheme, challenges arose due to the open-loop design and inherent perturbations in the learned matrices, resulting in control failures. To address this, an extra feedback loop was introduced into the network, modifying the definition of $\bmu{c}$ to incorporate error feedback. Although error feedback showed overall improvement, the errors remained unacceptably high when working with two networks in series. In a separate exploration, a single network was constructed, combining both approaches. By adopting the control network's definition of $\bmu{c}$, results were comparable to the two network approach. However, this came with the prohibitive restriction of necessitating $\bmu{B} = \bmu{I}$. Attempts to enable orthonormal input matrices into the network were possible, though limited by the mandatory use of the analytically computed matrices in stage one. The addition of feedback did not give any improved results.\\

The primary limitation stems from inaccuracies in $\bmu{W}^s$. Under the premise that a highly accurate $\bmu{W}^s$ could be learned, either method can yield viable results for control.\\
Overall, the network and learning rule choices align with biological plausibility. However, the chosen control scheme as well as the construction of the single network is questionable. It remains unclear the whether plausible learning rules for the control network exist. Additionally, the computation of $\bmu{c}$ requiring the target state, its derivative and the system matrix itself bring the entire control aspect in question.\\

All in all, the goal of creating a controller for arbitrary systems was not fully achieved. Due to limitations in control as well as in learning the use cases for the presented scheme are highly limited if analytically computed matrices are not utilized. Additionally, the inherent tuning of for different systems makes the approach inviable as a "black box."\\
Nonetheless, control can be obtained if additional information is available and conditions are met. Under these assumptions, control can be accurate with up to a single spike difference from the target, highlighting the \ac{SNN}'s immense potential.

\section{Future Work}
There are a numerous ways to build upon the work that presented here. These extensions can be grouped into enhancing the capabilities, incorporating more biological plausibility, or topics that warrant further investigation.
\subsubsection{Extending capabilities}
\paragraph{Learning of  $\bmu{\Gamma}$}\mbox{}\\
A straightforward step to enhance our network's learning capabilities involves allowing the learning of the Feed-Forward weights $\bmu{\Gamma}$, as proposed in \cite{brendel_learning_2020}. While this has been briefly attempted here, the rigorous integration and testing is lacking.\\
In first tests, the combination of feed-forward training and the learning of $\bmu{W}^s$ was unsuccessful and requires further research.
\paragraph{Learning during Control}\mbox{}\\
In most neural networks, training and testing are two distinct phases in the deployment process. Similarly, in our network, training demands a white noise process to enable optimal firing of all neurons. Training with non-zero mean signals, e.g already a desired reference trajectory in a control setting, could enable the network to adapt to a changing environment and significantly enhance its capabilities. Combining feed-forward learning and training non-whitened input using the covariance matrix $\bmu{\Sigma} = \text{cov}(\bmu{x},\bmu{x})$ and recentring the input $\bmu{x
}_c = \bmu{x} - \langle \bmu{x}\rangle$ by its mean, as seen in \cite{vertechi_unsupervised_2014} could yield interesting results.\\

Another intriguing approach to enable continual learning is to further integrate the in \cref{sssec:plasticity} mentioned methods of \ac{EWC}. While this has not been researched for \acp{SNN} yet, it could potentially open ways to build networks that can increase in their neuron count or the number of represented states over time. Adding neurons while the network is active and training could give a more adaptable controller, activating "sleeping neurons" if the problem at hand requires more robustness or precision.\\

\paragraph{Non-linear systems and Control}
The restriction to linear systems poses limits on the applicability to broader set of problems. To that, methods have already been revised to extend the simulation to non-linear problems \cite{alemi_learning_2017}. By using sigmoid basis functions dependent on the firing rate instead of linear $\bmu{r}$ itself, non-linearities are introduced. A matrix similar to $\bmu{W}^s$ is then trained by the student-teacher approach presented here using a slightly adopted learning rule.

\subsubsection{Biologic plausibility}
\paragraph{Dale's Law}\mbox{}\\
There are some immediate developments available. First of all could be the implementation of Dale's Law.\\
Following Dale's principle, it is not possible for a neuron to act as an excitatory and inhibitory neuron at the same time. In the network built in this project, this has been ignored for simplicity. In order to adhere to Dale's law, it would be necessary to separate groups of excitatory and inhibitory neurons that interact both with themselves and each other. This would also require an adjustment of the learning rules and can be implemented following the supplementary material of \cite{brendel_learning_2020}.\\
\paragraph{Synaptic Delays}\mbox{}\\
Another increase of biological plausibility would be the integration of synaptic delays. In this implementation of network architecture, a spike is processed within the same time-step and as such changes the network instantaneously.  In \cite{rullan_buxo_poisson_2020}, the authors show that the addition of delays results in the network ping-ponging, the rapidly alternating firing of spikes. They propose conditionally Poisson firing neurons that allow for synaptic delays while retaining the network accuracy and robustness.\\

\subsubsection{Investigating}
\paragraph{Different Noise Types}\mbox{}\\
The previous study on the input sequences for learning could be extended upon with a more rigorous testing and examination of spiking behaviour. Additionally, different noise types could be considered, not limited to white noise. During testing, inputs with less smoothing yielded better results. This was attributed to fast-changing signal inputs causing an increase of error, spiking and subsequent parameter adjustment. This could be explored further using Blue or violet noise.
\paragraph{Spiking Imbalance}
In addition to investigating the noise, spiking behaviour during learning also merits further exploration. During training, the system matrix $\bmu{A}$ had significant influence over the spike distribution over neurons. This resulted only a couple of neurons contributing to more than 90\% of total spikes at the end of training. It was found that eigenvalue grouping appears to be the main factor in the spike distribution.\\
It is desirable that spikes during training are as evenly distributed as possible, as the least trained neuron causes the highest error. Therefore this imbalance can lead prolonged training times. However, since the system matrix $\bmu{A}$ is known, adapting training input to the system could improve spike distribution and, consequently, reduce training time.\\

\section{Final Words}

All in all, the network demonstrates the capability of controlling a dynamic system. However, the limitations set mostly by the control concept makes the realistic use of this approach impossible. The requirement on the input matrix $\bmu{B} = \bmu{I}$ for the presented approach is fundamentally restrictive and therefore demands the use of the exact, instead of the learned, matrices. Meanwhile even when the necessary conditions for control in stage 2 are met, network performance can still be subpar, necessitating further investigation.\\

Nonetheless the found accuracy as well as the proven robustness by previous authors given by a discrete spiking neural network in the context of biologically plausibility was impressive, fulfilling the set out goal in the beginning in accuracy as well as on robustness and noise thanks to the chosen network architecture. If all necessary conditions are met and the additional information is available, the control can produce acceptable performance that might be useful in specific tasks.



