\chapter{<Conclusions>}
Describe the conclusions (reflect on the whole introduction given in Chapter 1).

Discuss the positive effects and the drawbacks.

Describe the evaluation of the results of the degree project.

Describe valid future work.

The sections below are optional but could be added here.


In the end, we build a controller in three stages to control a linear system. The controller is based on \acp{SNN} using the Efficient balanced coding scheme with biologic plausibility. In this framework the first stage, the simulation, was capable of simulating any given dynamical system using analytically calculated values.\\
As a second step, a controller was devised to create the control signal $\bmu{u}$. The controller was using the same \ac{SNN} architecture and was supposed to be used in conjunction with the previous stage. The control signal or even the spikes would have been fed to the simulating network. However this idea was dismissed due to its problems in the implementation and function of the controller. Furthermore, the necessary conditions for the controller to work are prohibitively high that a realisation was deemed to only bring marginal benefits. Furthermore the dynamics of the controlling capabilities were predominantly stemming from the definition of the external inputs $\bmu{c}$ instead of the whole network. For control, $\bmu{c}$ acted as a forcing term to the network bridging the necessary input to push the network into following the desired trajectory. This purely open loop design faced the classic issues of open loop designs e.g in aspects of noise. In a separate similar derivation the emerging explicit error term was insignificant in most test cases as well. These limitations in addition to the lack of a conceivable learning rule resulted that only the definition of $\bmu{c}$ was adopted for control.\\
Lastly, the analytically derived network dynamics were learned with local learning rules. The fast recurrent dynamics were learned by an unsupervised learning rule while the slow dynamics trained by a supervised student-teacher approach. The learning performance was examined and parameters tuned to allowing for a significant improvement in network accuracy for our model problem. Challenges in the learning process were primarily connected to the random initialization of the matrices intended for training, the scaling of learning rate, form of training input sequences and initialization of $\bmu{\Gamma}$. Higher-dimensional problems, in general, were only applicable in specific cases with manual parameter tuning, yielding mixed results overall.\\
In the last step, the previously learned matrices were run with the simulation build in stage one with the control scheme copied from the approaches in stage two. Due to the open loop design and the inherent perturbations in the learned matrices, the control was failing. With the addition of an extra feedback loop into the network, the definition of $\bmu{c}$ was slightly altered to incorporate error feedback.
Although the feedback greatly improved performance, the hope it was unable to work on non-zero initialized trained matrices that previously led to divergence even in mere simulation was not fulfilled.\\
Fortunately, the introduced feedback loop could be integrated the network itself and moreover learned automatically, given the initialization was zero.\\

\todo[inline]{is the feeding of the dot x and Ax even biologically plausible. Likely not.... ASK ARVIND}

\todo{maybe this is the final words section? Think about where to put this}
All in all, the network is capable of controlling a dynamic system. However the limitations set mostly by the control idea makes the realistic use of this approach impossible. The requirement on the input matrix $\bmu{B} = \bmu{I}$ for the presented approach is fundamentally restrictive and therefore unusable. Meanwhile even when the necessary conditions for control in stage 2 are met, network performance can still be subpar, requiring further investigation.\\

Nonetheless the found accuracy as well as the proven robustness by previous authors given by a discrete spiking neural network in the context of biologically plausible was impressive, fulfilling the set out goal in the beginning.\\

\todo[inline]{Results should be somehow generalizable to LSM and NEF using the paper i dont understand form Emil and Arvind}
\todo[inline]{Is it a limitation or biologic problem that it is not deep?}
\subsection{Future Work}

There are a plethora of ways to extend upon the work that has been done here. These can be grouped into extending the capabilities, adding more biologic plausibility or topics that merit further investigation.
\subsubsection{Extending capabilities}
\paragraph{Learning of $\bmu{\Gamma}$}
A straight forward step to expand the learning in our network would be to allow learning of the decoder $\bmu{\Gamma}$ from \cite{brendel_learning_2020}. While this has been briefly attempted here, the rigorous integration and testing is lacking.\\
In first tests, the combination of feed-forward training and the learning of $\bmu{W}^s$ was unsuccessful and requires further research.
\paragraph{Learning during Control}
As it is common in most neural networks, training and testing form 2 different steps in the networks deployment. Also here this is required as training demands a white noise process to enable firing of all neurons. Training with non-zero mean signals, e.g already a desired reference trajectory in a control setting, could enable the network to adopt to changing a changing environment and greatly improve its capabilities. With a combination feed-forward learning and training non-whitened input using the covariance matrix $\bmu{\Sigma} = \text{cov}(\bmu{x},\bmu{x})$ and recentering the input $\bmu{x
}_c = \bmu{x} - <x>$ by its mean seen in \cref{vertechi_unsupervised_2014} could show interesting results.\\
Another interesting approach to enable continual learning would be to further integrate the in \cref{sssec:plasticity} mentioned methods of \ac{EWC}. While this has not been researched yet for \acp{SNN}, it could potentially open ways to build networks that can increase in their neuron count or the number of represented states over time. Adding neurons while the network is active and training could give a more adaptable controller, activating "sleeping neurons" if the problem at hand requires more robustness or more precise results.\\

\paragraph{Non-linear systems and Control}
The restriction to linear function poses limits on the applicability to broader systems. To that, methods have already been revised to extend the simulation to non-linear problems \cite{alemi_learning_2017}. By using sigmoid basis functions dependent on the firing rate instead of linear $\bmu{r}$ itself, non-linearities are introduced. A matrix similar to $\bmu{W}^s$ is then trained by the student-teacher approach presented here using a slightly adopted learning rule.


\subsubsection{Biologic plausibility}
On the biologic side
Dale's law integration
Add synaptic delays and aka delay of synaptic transmissions


\todo[inline]{Keep this in as well?}
\subsubsection{Investigating}
\paragraph{Different noise types}
The previously done study on the input sequences for learning could be extended upon with a more rigorous testing and examination of spiking behaviour. Additionally, different noise types could be considered except of white noise. During testing, Inputs with less smoothing yielded better results. This was attributed to fast changing signal input causing an increase of error, spiking and subsequent adjustment or parameters. This could be tested further using Blue or violet noise.
\paragraph{Spiking Imbalance}
In addition to investigating the noise, spiking behaviour during learning also merits further investigation. During training, the system matrix $\bmu{A}$ had significant influence over the spike distribution over neurons. This caused that at the end of training only a couple of neurons could amount to more than 90\% of total spikes during learning. It was found that eigenvalue grouping appears to be the main factor in the spike distribution.\\
It is desirable that spikes in training are as distributed as possible due to the least trained neuron causing the highest error. Therefore this imbalance can cause prolonged training times. But as the system matrix $\bmu{A}$ is known, adapting training input to the system could improve spike distribution and therefore shorter training time.\\

\subsection{Final Words}
\todo[inline]{what to put here?}
\todo[inline]{Write an acknoledgement}
\todo[inline]{did i write that Gamma still worked but gave a bit worse results?}
\todo[inline]{Write that there was also a lot of handtuning involved and it makes it unusable}
\listoftodos



